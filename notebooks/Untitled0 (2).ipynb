{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1FwWkUJzWB8Tg52G7MrB9wv8-Ds5_tkbc","authorship_tag":"ABX9TyPbfDB8hu/sxCE7aMeFNufp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":34,"metadata":{"id":"j7JkUCebrGRO","executionInfo":{"status":"ok","timestamp":1760272913379,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"outputs":[],"source":["# %load_ext cuml.accel\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os  # 导入os库来处理文件和目录\n","import glob # 导入glob库来查找文件\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import Ridge\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import r2_score, mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.decomposition import PCA\n","from scipy.signal import welch\n","from tqdm import tqdm"]},{"cell_type":"code","source":["\n","\n","# def load_all_segments(root_dir, eeg_suffix='EEG_aligned.npy', sound_suffix='Sound_aligned.npy', root_suffix='feature_normalized'):\n","\n","#     eeg_segments_list = []\n","#     sound_segments_list = []\n","\n","#     subject_folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n","\n","#     if not subject_folders:\n","#         print(f\"错误: 在 '{root_dir}' 中没有找到任何被试者文件夹。\")\n","#         return None, None\n","\n","#     print(f\"找到了 {len(subject_folders)} 个被试者...\")\n","\n","#     for subject in subject_folders:\n","#         subject_path = os.path.join(root_dir, subject, root_suffix)\n","\n","#         eeg_files = glob.glob(os.path.join(subject_path, f'*{eeg_suffix}'))\n","\n","#         if not eeg_files:\n","#             continue\n","\n","#         for eeg_file_path in eeg_files:\n","#             base_name = os.path.basename(eeg_file_path).replace(eeg_suffix, '')\n","#             sound_file_path = os.path.join(subject_path, base_name + sound_suffix)\n","\n","#             if os.path.exists(sound_file_path):\n","#                 try:\n","#                     eeg_segment = np.load(eeg_file_path)\n","#                     sound_segment = np.load(sound_file_path)\n","\n","\n","#                     if eeg_segment.shape[0] == sound_segment.shape[0]:\n","#                         eeg_segments_list.append(eeg_segment)\n","#                         sound_segments_list.append(sound_segment)\n","#                 except Exception as e:\n","#                     print(f\"加载文件 {os.path.basename(eeg_file_path)} 时出错: {e}\")\n","\n","#     if not eeg_segments_list:\n","#         print(\"错误: 未能加载任何有效的数据段。\")\n","#         return None, None\n","\n","#     # --- 最终修改在这里 ---\n","#     # 我们不再使用 np.vstack\n","#     # 直接返回包含所有数据段的列表\n","#     print(f\"\\n加载完成！总共加载了 {len(eeg_segments_list)} 个数据段。\")\n","#     return eeg_segments_list, sound_segments_list\n","\n","def load_segments_with_subject_ids(root_dir, eeg_suffix='EEG_aligned.npy', sound_suffix='Sound_aligned.npy', root_suffix='feature_normalized'):\n","    eeg_segments_list = []\n","    sound_segments_list = []\n","    subject_ids_list = [] # 新增一个列表来存储ID\n","\n","    print(f\"开始从根目录 '{root_dir}' 加载数据段及被试者ID...\")\n","\n","    subject_folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n","\n","    for subject in tqdm(subject_folders, desc=\"处理被试者\"):\n","        subject_path = os.path.join(root_dir, subject, root_suffix)\n","        eeg_files = glob.glob(os.path.join(subject_path, f'*{eeg_suffix}'))\n","\n","        for eeg_file_path in eeg_files:\n","            base_name = os.path.basename(eeg_file_path).replace(eeg_suffix, '')\n","            sound_file_path = os.path.join(subject_path, base_name + sound_suffix)\n","\n","            if os.path.exists(sound_file_path):\n","                try:\n","                    eeg_segment = np.load(eeg_file_path)\n","                    sound_segment = np.load(sound_file_path)\n","\n","                    if eeg_segment.shape[0] == sound_segment.shape[0]:\n","                        eeg_segments_list.append(eeg_segment)\n","                        sound_segments_list.append(sound_segment)\n","                        subject_ids_list.append(subject) # 关键：记录下当前数据段属于哪个被试者\n","                except Exception as e:\n","                    print(f\"加载文件 {os.path.basename(eeg_file_path)} 时出错: {e}\")\n","\n","    print(f\"\\n加载完成！总共加载了 {len(eeg_segments_list)} 个数据段。\")\n","    return eeg_segments_list, sound_segments_list, subject_ids_list\n"],"metadata":{"id":"jdJxzG6xl7Uh","executionInfo":{"status":"ok","timestamp":1760272914210,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["ROOT_DATA_DIR = r'/content/drive/MyDrive/data'\n","\n","\n","# 假设你的原始数据段文件名后缀是 '_eeg_segment.npy' 和 '_sound_segment.npy'\n","# 请务必根据你的实际情况修改！\n","\n","# 调用新函数\n","eeg_segments, sound_segments, subject_ids_list = load_segments_with_subject_ids(ROOT_DATA_DIR)\n","\n","# 检查一下我们的“档案箱”里有什么\n","if eeg_segments is not None:\n","    print(\"\\n--- 加载结果检查 ---\")\n","    print(f\"eeg_segments 是一个列表，长度为: {len(eeg_segments)}\")\n","    print(f\"列表中的第一个EEG数据段的形状是: {eeg_segments[0].shape}\")\n","    print(f\"列表中的第二个EEG数据段的形状是: {eeg_segments[1].shape}\")\n","\n","    print(f\"\\nsound_segments 也是一个列表，长度为: {len(sound_segments)}\")\n","    print(f\"列表中的第一个声音数据段的形状是: {sound_segments[0].shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFll4HjnmS4U","executionInfo":{"status":"ok","timestamp":1760272936645,"user_tz":-180,"elapsed":20869,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"0c972126-8a8e-4a38-bd02-8ae7aa6bc02c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [00:20<00:00,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1794 个数据段。\n","\n","--- 加载结果检查 ---\n","eeg_segments 是一个列表，长度为: 1794\n","列表中的第一个EEG数据段的形状是: (364, 32)\n","列表中的第二个EEG数据段的形状是: (364, 32)\n","\n","sound_segments 也是一个列表，长度为: 1794\n","列表中的第一个声音数据段的形状是: (364, 54)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["SAMPLING_RATE = 256\n","BANDS = {\n","    'delta': [1, 4],    # 1-4 Hz\n","    'theta': [4, 8],    # 4-8 Hz\n","    'alpha': [8, 13],   # 8-13 Hz\n","    'beta': [13, 30],   # 13-30 Hz\n","    'gamma': [30, 50]   # 30-50 Hz\n","}"],"metadata":{"id":"4mC8cKJnncHj","executionInfo":{"status":"ok","timestamp":1760272941953,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def extract_features_from_segments(eeg_segment, sound_segment, sampling_rate, bands):\n","    \"\"\"\n","    对单个数据段进行特征提取\n","    eeg_segment: 形状为 (n_samples, 32) 的EEG数据段\n","    sound_segment: 形状为 (n_samples, 54) 的声音数据段\n","    \"\"\"\n","\n","    # --- 1. 提取EEG的频域特征 (生成 X 的一行) ---\n","    psd_features = []\n","    # 遍历32个EEG通道\n","    for channel_index in range(eeg_segment.shape[1]):\n","        # 使用welch方法计算功率谱密度(PSD)\n","        # freqs: 频率点, psd: 对应频率点的能量\n","        freqs, psd = welch(eeg_segment[:, channel_index], fs=sampling_rate, nperseg=sampling_rate) # 用1秒的窗口计算\n","\n","        # 计算每个预定义频带的平均能量\n","        for band, freq_range in bands.items():\n","            # 找到落在当前频带内的频率点的索引\n","            band_indices = np.where((freqs >= freq_range[0]) & (freqs <= freq_range[1]))[0]\n","            # 计算这些频率点上的平均能量，如果没找到则为0\n","            band_power = np.mean(psd[band_indices]) if len(band_indices) > 0 else 0\n","            psd_features.append(band_power)\n","\n","    # --- 2. 计算声音特征的均值作为目标 (生成 Y 的一行) ---\n","    sound_features_mean = np.mean(sound_segment, axis=0)\n","\n","    return np.array(psd_features), sound_features_mean\n","\n","# --- 整合流水线: 遍历所有数据段并提取特征 ---\n","X_new = []\n","Y_new = []"],"metadata":{"id":"XTw_zJ-JoZcr","executionInfo":{"status":"ok","timestamp":1760272942751,"user_tz":-180,"elapsed":7,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["for i in tqdm(range(len(eeg_segments)), desc=\"提取特征中\"):\n","    eeg_seg = eeg_segments[i]\n","    sound_seg = sound_segments[i]\n","\n","    # 调用核心函数\n","    x_feat, y_mean = extract_features_from_segments(eeg_seg, sound_seg, SAMPLING_RATE, BANDS)\n","\n","    X_new.append(x_feat)\n","    Y_new.append(y_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NN5Ck7NToj1a","executionInfo":{"status":"ok","timestamp":1760272977351,"user_tz":-180,"elapsed":33097,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"ac378b5a-8d3d-4af8-9fe6-b55286f56887"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["提取特征中: 100%|██████████| 1794/1794 [00:33<00:00, 54.21it/s]\n"]}]},{"cell_type":"code","source":["X_df = pd.DataFrame(X_new)\n","X_df['subject'] = subject_ids_list\n","\n","# 创建StandardScaler实例\n","scaler = StandardScaler()\n","\n","# 创建一个空列表来收集处理好的数据块\n","normalized_blocks = []\n","\n","# 使用 groupby 循环，为每个被试者独立进行标准化\n","for subject_name, subject_data in tqdm(X_df.groupby('subject'), desc=\"按被试者归一化\"):\n","    # 分离出特征列\n","    features = subject_data.drop('subject', axis=1)\n","    # 对当前被试者的数据块进行 fit_transform\n","    normalized_features = scaler.fit_transform(features)\n","    # 将处理好的数据块存入列表\n","    normalized_blocks.append(pd.DataFrame(normalized_features, index=features.index))\n","\n","# 将所有标准化的数据块重新合并\n","X_final_df = pd.concat(normalized_blocks).sort_index()\n","X_final = X_final_df.to_numpy()\n","\n","# Y 通常进行全局处理，因为它是我们的目标标准\n","Y_final = Y_new"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCg5GFifbaSl","executionInfo":{"status":"ok","timestamp":1760272909401,"user_tz":-180,"elapsed":106,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"b88f20cb-5378-4d51-c194-b207a4363301"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["按被试者归一化: 100%|██████████| 15/15 [00:00<00:00, 167.35it/s]\n"]}]},{"cell_type":"code","source":["# 将结果列表转换为Numpy数组\n","X_final = np.array(X_final)\n","Y_final = np.array(Y_final)\n","\n","print(\"\\n--- 特征提取完成！---\")\n","print(\"最终数据集已生成。\")\n","print(f\"新特征矩阵 X_new 的形状: {X_final.shape}\")\n","print(f\"新目标矩阵 Y_new 的形状: {Y_final.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uaYz7gXouEj","executionInfo":{"status":"ok","timestamp":1760273039232,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"a6471447-bd5c-4ccd-dc96-0b9f9c632e9a"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 特征提取完成！---\n","最终数据集已生成。\n","新特征矩阵 X_new 的形状: (1794, 160)\n","新目标矩阵 Y_new 的形状: (1794, 54)\n"]}]},{"cell_type":"code","source":["\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","    X_final, Y_final, test_size=0.2, random_state=42\n",")\n","print(\"新数据集划分完成。\")\n","print(f\"X_train 形状: {X_train.shape}, Y_train 形状: {Y_train.shape}\")\n","\n","\n","# =============================================================================\n","# 步骤 2: 对 Y (目标) 进行提纯\n","# 即使是Y_new，原始的54个特征维度依然存在冗余，所以我们重复之前的成功经验\n","# =============================================================================\n","print(\"\\n正在对目标数据 Y 进行“填充-标准化-PCA”提纯...\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMgh6yugpD_y","executionInfo":{"status":"ok","timestamp":1760273042375,"user_tz":-180,"elapsed":20,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"e0e68a4f-d124-4957-c1cb-3df8253d7825"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["新数据集划分完成。\n","X_train 形状: (1435, 160), Y_train 形状: (1435, 54)\n","\n","正在对目标数据 Y 进行“填充-标准化-PCA”提纯...\n"]}]},{"cell_type":"code","source":["# 创建并配置Y的处理工具\n","imputer_y = SimpleImputer(strategy='mean')\n","scaler_y = StandardScaler()\n","# 让PCA自动选择能保留95%信息的主成分数量\n","pca_y = PCA(n_components=0.95)\n","\n","# 对训练集进行fit_transform\n","Y_train_imputed = imputer_y.fit_transform(Y_train)\n","Y_train_scaled = scaler_y.fit_transform(Y_train_imputed)\n","Y_train_pca = pca_y.fit_transform(Y_train_scaled)\n","\n","# 对测试集只进行transform\n","Y_test_imputed = imputer_y.transform(Y_test)\n","Y_test_scaled = scaler_y.transform(Y_test_imputed)\n","Y_test_pca = pca_y.transform(Y_test_imputed)\n","\n","print(f\"Y 已被成功提纯至 {pca_y.n_components_} 个主成分。\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Rb1vHVQqHci","executionInfo":{"status":"ok","timestamp":1760273045606,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"ece549de-b62b-4584-81e9-3b8e30ca65ab"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Y 已被成功提纯至 25 个主成分。\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: [52]. At least one non-missing value is needed for imputation with strategy='mean'.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: [52]. At least one non-missing value is needed for imputation with strategy='mean'.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print(\"\\n正在对输入数据 X (频域特征) 进行标准化...\")\n","scaler_x = StandardScaler()\n","X_train_scaled = scaler_x.fit_transform(X_train)\n","X_test_scaled = scaler_x.transform(X_test)\n","\n","\n","print(\"\\n开始训练最终的随机森林模型...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdIXaWugqEnZ","executionInfo":{"status":"ok","timestamp":1760273046698,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"b9a08c40-8b4a-4af8-8fbc-df50000494ee"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","正在对输入数据 X (频域特征) 进行标准化...\n","\n","开始训练最终的随机森林模型...\n"]}]},{"cell_type":"code","source":["final_rf_model = RandomForestRegressor(\n","    n_estimators=200,       # 更多的树\n","    random_state=42,\n","    n_jobs=-1,              # 使用所有CPU核心\n","    max_depth=25,           # 可以探索更深的关系\n","    min_samples_leaf=5,     # 防止过拟合\n","    max_features='sqrt'     # 一种常用的特征选择策略\n",")\n","\n","# 使用处理好的数据进行训练\n","final_rf_model.fit(X_train_scaled, Y_train_pca)\n","print(\"模型训练完成!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8tibi-UqBnb","executionInfo":{"status":"ok","timestamp":1760273055242,"user_tz":-180,"elapsed":7544,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"07d4bfde-9308-4de6-9fcc-eba04ba2bac7"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["模型训练完成!\n"]}]},{"cell_type":"code","source":["Y_pred = final_rf_model.predict(X_test_scaled)\n","\n","# 使用处理后的Y_test_pca来计算分数\n","R2_final = r2_score(Y_test_pca, Y_pred)\n","RMSE_final = np.sqrt(mean_squared_error(Y_test_pca, Y_pred))\n","\n","print(f\"\\n--- ✨ 最终模型评估结果 ✨ ---\")\n","print(f\"R² 分数: {R2_final:.4f}\")\n","print(f\"均方根误差 (RMSE): {RMSE_final:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGthyUR7p_rl","executionInfo":{"status":"ok","timestamp":1760273056840,"user_tz":-180,"elapsed":91,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"52021392-7747-4ee9-a278-41e6da1a879d"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- ✨ 最终模型评估结果 ✨ ---\n","R² 分数: -31.7461\n","均方根误差 (RMSE): 563.4269\n"]}]},{"cell_type":"code","source":["Y_new_df = pd.DataFrame(Y_new)\n","print(f\"净化前 Y 的形状: {Y_new_df.shape}\")\n","\n","# .dropna(axis=1, how='all') 会删除那些“所有”值为NaN的列\n","Y_new_cleaned_df = Y_new_df.dropna(axis=1, how='all')\n","\n","# 检查删除了多少列\n","n_dropped = Y_new_df.shape[1] - Y_new_cleaned_df.shape[1]\n","print(f\"检测到并删除了 {n_dropped} 个完全无效的特征列。\")\n","print(f\"净化后 Y 的形状: {Y_new_cleaned_df.shape}\")\n","\n","# 将清理干净的DataFrame转回Numpy数组\n","Y_new_cleaned = Y_new_cleaned_df.to_numpy()"],"metadata":{"id":"OJyrBjMH0sPW","executionInfo":{"status":"ok","timestamp":1760272819273,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"dec6015f-8de2-4c57-ab64-348a058e281a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["净化前 Y 的形状: (1794, 54)\n","检测到并删除了 1 个完全无效的特征列。\n","净化后 Y 的形状: (1794, 53)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# --- 假设您的 X_new 和 Y_new_cleaned 已经在这里准备好了 ---\n","# X_new 的形状是 (1794, 160)\n","# Y_new_cleaned 的形状是 (1794, 53)\n","\n","print(\"\\n--- 开始进行地毯式数据排查，寻找极端异常值 ---\")\n","\n","# =============================================================================\n","# 步骤 1: 排查输入数据 X_new\n","# =============================================================================\n","X_new_df = pd.DataFrame(X_new)\n","\n","# .describe() 会计算每一列的基本统计数据\n","# 我们用 .T 来转置表格，让每一行代表一个特征，更方便查看\n","print(\"\\n--- 输入数据 X_new (频域特征) 的统计描述 ---\")\n","X_stats = X_new_df.describe().T\n","\n","# 筛选出可能存在问题的特征\n","# 比如，如果一个特征的标准差(std)为0，说明它是一个常数，没有信息量\n","# 或者，如果最大值(max)比75%分位数(75%)大几个数量级，说明有极端大值\n","potential_issues_X = X_stats[\n","    (X_stats['std'] == 0) |\n","    (X_stats['max'] > X_stats['75%'] * 1000) |\n","    (X_stats['min'] < X_stats['25%'] * -1000)\n","]\n","\n","print(\"X_new 的总体统计信息:\")\n","print(X_stats)\n","\n","if not potential_issues_X.empty:\n","    print(\"\\n\\n⚠️  警告: 在 X_new 中发现以下可能存在问题的特征! ⚠️\")\n","    print(potential_issues_X)\n","else:\n","    print(\"\\n✅  在 X_new 中未检测到明显的极端异常值。\")\n","\n","\n","# =============================================================================\n","# 步骤 2: 排查目标数据 Y_new_cleaned\n","# =============================================================================\n","Y_new_cleaned_df = pd.DataFrame(Y_new_cleaned)\n","\n","print(\"\\n\\n--- 目标数据 Y_new_cleaned (声音特征) 的统计描述 ---\")\n","Y_stats = Y_new_cleaned_df.describe().T\n","\n","potential_issues_Y = Y_stats[\n","    (Y_stats['std'] < 1e-9) | # 标准差极小也可能是问题\n","    (Y_stats['max'] > Y_stats['75%'] * 1000) |\n","    (Y_stats['min'] < Y_stats['25%'] * -1000)\n","]\n","\n","print(\"Y_new_cleaned 的总体统计信息:\")\n","print(Y_stats)\n","\n","if not potential_issues_Y.empty:\n","    print(\"\\n\\n⚠️  警告: 在 Y_new_cleaned 中发现以下可能存在问题的特征! ⚠️\")\n","    print(potential_issues_Y)\n","else:\n","    print(\"\\n✅  在 Y_new_cleaned 中未检测到明显的极端异常值。\")"],"metadata":{"id":"stfUYmWT0tiV","executionInfo":{"status":"ok","timestamp":1760272825136,"user_tz":-180,"elapsed":346,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"7789d4a5-91ea-4bba-e192-a95272f96af4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 开始进行地毯式数据排查，寻找极端异常值 ---\n","\n","--- 输入数据 X_new (频域特征) 的统计描述 ---\n","X_new 的总体统计信息:\n","      count       mean         std       min       25%       50%        75%  \\\n","0    1794.0  27.290155  249.036224  0.014948  0.851436  2.199614   6.371983   \n","1    1794.0   1.289290    3.243106  0.006319  0.307415  0.630476   1.350802   \n","2    1794.0   0.605428    0.836866  0.004161  0.169716  0.353031   0.750296   \n","3    1794.0   1.047234    1.431301  0.004722  0.267107  0.582395   1.298471   \n","4    1794.0   0.450130    0.670071  0.001968  0.122812  0.253539   0.513840   \n","..      ...        ...         ...       ...       ...       ...        ...   \n","155  1794.0  34.369045  135.580307  0.001199  2.163420  6.406597  16.866975   \n","156  1794.0   3.112349    4.347631  0.000518  0.671451  1.847828   4.004209   \n","157  1794.0   1.379851    1.493446  0.000404  0.425604  1.012424   1.851448   \n","158  1794.0   3.113666    3.823667  0.000670  0.780597  1.698474   4.244743   \n","159  1794.0   2.180722    4.405178  0.000611  0.275694  0.859563   2.478976   \n","\n","             max  \n","0    9087.330078  \n","1      73.668877  \n","2      11.500037  \n","3      11.724245  \n","4       7.794337  \n","..           ...  \n","155  2988.341553  \n","156    52.166481  \n","157    17.522017  \n","158    30.420235  \n","159    52.088058  \n","\n","[160 rows x 8 columns]\n","\n","\n","⚠️  警告: 在 X_new 中发现以下可能存在问题的特征! ⚠️\n","      count        mean          std           min       25%       50%  \\\n","0    1794.0   27.290155   249.036224  1.494824e-02  0.851436  2.199614   \n","10   1794.0   63.824120   895.968384  2.466399e-04  0.555539  2.363008   \n","20   1794.0   21.467199   305.173828  7.420980e-04  0.143929  0.760381   \n","25   1794.0   64.598297   623.327332  3.299548e-02  1.566471  4.064393   \n","35   1794.0   24.569826   301.599274  5.562971e-03  0.398688  1.335569   \n","40   1794.0   56.605724   776.981689  3.281496e-02  1.008042  2.801649   \n","55   1794.0   22.683790   214.439438  1.080540e-04  0.109348  0.813893   \n","85   1794.0   22.700464   211.454391  1.331311e-07  0.260436  1.169072   \n","90   1794.0   61.831009   717.056946  1.620451e-02  1.971664  5.444456   \n","100  1794.0   98.004066  1800.712891  1.066779e-01  3.235488  6.714761   \n","105  1794.0  117.989426  2269.443604  2.793242e-02  1.361804  3.646792   \n","115  1794.0   68.331161   732.901489  5.161368e-03  2.018972  6.193262   \n","120  1794.0   61.294689   732.234192  3.500623e-02  1.609092  4.964798   \n","140  1794.0   31.613142   328.821167  5.479189e-02  1.078741  3.209147   \n","\n","           75%           max  \n","0     6.371983   9087.330078  \n","10    7.889592  33776.746094  \n","20    3.598216  11807.762695  \n","25   13.263215  20602.009766  \n","35    4.769617  11803.763672  \n","40    8.046304  30404.085938  \n","55    3.755066   6295.920410  \n","85    4.207179   5906.878906  \n","90   14.557320  27588.656250  \n","100  14.934465  64547.796875  \n","105  11.331075  75931.507812  \n","115  16.422050  28901.845703  \n","120  14.170645  26094.718750  \n","140   8.529384  11533.179688  \n","\n","\n","--- 目标数据 Y_new_cleaned (声音特征) 的统计描述 ---\n","Y_new_cleaned 的总体统计信息:\n","     count         mean           std          min          25%          50%  \\\n","0   1794.0  -470.050720  6.031594e+01  -638.181213  -493.909241  -461.944916   \n","1   1794.0    57.063587  3.912836e+01   -12.676420    23.741756    46.455185   \n","2   1794.0     2.162170  1.321275e+01   -35.646679    -5.782913     2.054442   \n","3   1794.0    15.715966  1.443204e+01    -9.247281     3.283822    13.017644   \n","4   1794.0   -13.781521  1.406618e+01   -49.572872   -21.916519   -11.631197   \n","5   1794.0    -4.522140  7.913166e+00   -20.664915   -10.280624    -5.429566   \n","6   1794.0   -15.373235  7.370799e+00   -34.290909   -20.675146   -15.479896   \n","7   1794.0    -8.971362  6.179687e+00   -23.111113   -13.198444    -9.163463   \n","8   1794.0   -13.942215  8.802371e+00   -36.160545   -21.201115   -13.789647   \n","9   1794.0    -6.030565  4.220081e+00   -17.253183    -8.469540    -5.351323   \n","10  1794.0    -9.332506  3.838567e+00   -18.818361   -11.493132    -9.499219   \n","11  1794.0    -1.450368  4.256322e+00   -13.278951    -3.812079    -1.297798   \n","12  1794.0    -7.069556  3.905807e+00   -18.234789    -9.725375    -6.942660   \n","13  1794.0     0.129775  7.690545e-01    -2.561882    -0.195643     0.084362   \n","14  1794.0     0.000840  3.573075e-01    -1.643914    -0.041706     0.011908   \n","15  1794.0     0.025269  3.640408e-01    -1.250387    -0.078744    -0.000823   \n","16  1794.0    -0.038380  2.595504e-01    -1.068002    -0.055086    -0.001948   \n","17  1794.0    -0.008332  2.792202e-01    -0.916198    -0.082592    -0.026915   \n","18  1794.0     0.016527  2.231801e-01    -0.712911    -0.048649    -0.008696   \n","19  1794.0     0.015298  2.021032e-01    -0.585848    -0.071887    -0.030056   \n","20  1794.0    -0.038302  2.715750e-01    -1.362082    -0.066753    -0.018023   \n","21  1794.0    -0.052010  2.106258e-01    -0.765947    -0.102566    -0.031019   \n","22  1794.0     0.011458  1.665649e-01    -0.729821    -0.039525    -0.006947   \n","23  1794.0     0.008911  2.175977e-01    -0.936341    -0.060816    -0.009889   \n","24  1794.0    -0.006182  1.768596e-01    -0.782298    -0.044478    -0.008088   \n","25  1794.0    -0.013713  1.942977e-01    -0.758730    -0.042033    -0.009310   \n","26  1794.0     0.047872  2.656124e-01    -0.985975    -0.028222     0.010255   \n","27  1794.0     0.030021  1.770434e-01    -0.639129    -0.029353    -0.004045   \n","28  1794.0     0.053852  1.994467e-01    -0.634004    -0.014186     0.002991   \n","29  1794.0     0.050817  1.768135e-01    -0.796793    -0.012226     0.004928   \n","30  1794.0     0.025059  1.444176e-01    -0.497829    -0.015684     0.001819   \n","31  1794.0     0.010289  1.469322e-01    -0.493729    -0.011293    -0.000136   \n","32  1794.0     0.008153  1.168695e-01    -0.439982    -0.019341    -0.000438   \n","33  1794.0    -0.000303  1.336106e-01    -0.677725    -0.012912    -0.000281   \n","34  1794.0     0.002418  1.256460e-01    -0.556236    -0.018367    -0.000323   \n","35  1794.0    -0.015927  1.493058e-01    -0.917669    -0.019623    -0.002913   \n","36  1794.0    -0.006140  1.398260e-01    -0.749391    -0.016092    -0.001542   \n","37  1794.0    -0.005879  1.588997e-01    -1.008433    -0.013370    -0.001105   \n","38  1794.0     0.007941  1.762973e-01    -0.947804    -0.012241     0.000188   \n","39  1794.0     0.084376  3.592278e-02     0.014803     0.055782     0.081540   \n","40  1794.0     0.163928  4.262184e-02     0.054688     0.132936     0.168753   \n","41  1794.0  1417.598633  2.892970e+02   755.501892  1207.494141  1460.771484   \n","42  1794.0  1173.890747  1.540142e+02   827.343079  1060.491699  1169.436768   \n","43  1794.0  2659.331299  5.500416e+02  1358.374146  2217.301758  2748.812256   \n","44  1794.0     0.088748  6.627336e-02     0.000255     0.038380     0.071095   \n","45    14.0    13.229795  9.896746e-07    13.229795    13.229795    13.229795   \n","46    14.0     5.942063  4.948373e-07     5.942063     5.942063     5.942063   \n","47    14.0    12.296373  1.979349e-06    12.296374    12.296374    12.296374   \n","48    14.0    13.781157  9.896746e-07    13.781157    13.781157    13.781157   \n","49    14.0    16.347080  1.979349e-06    16.347080    16.347080    16.347080   \n","50    14.0    30.792080  1.979349e-06    30.792080    30.792080    30.792080   \n","51    14.0    15.676671  1.979349e-06    15.676671    15.676671    15.676671   \n","52    14.0     0.413523  9.278200e-08     0.413523     0.413523     0.413523   \n","\n","            75%          max  \n","0   -424.323364  -355.909821  \n","1     88.714989   171.480820  \n","2     11.351695    30.508446  \n","3     27.613683    52.062847  \n","4     -3.513369    14.755736  \n","5      0.372821    13.091414  \n","6    -10.079907     2.650982  \n","7     -4.704797     5.416973  \n","8     -6.990566     7.928951  \n","9     -2.974723     4.608061  \n","10    -6.700928     2.305941  \n","11     0.531184    10.570538  \n","12    -4.599995     2.498079  \n","13     0.765658     1.305332  \n","14     0.121311     1.107511  \n","15     0.074504     2.314250  \n","16     0.038448     1.037140  \n","17     0.028528     1.718484  \n","18     0.033571     1.115180  \n","19     0.012126     0.981687  \n","20     0.014427     1.568107  \n","21     0.012084     1.264772  \n","22     0.028176     0.656098  \n","23     0.015840     1.239675  \n","24     0.016629     0.655183  \n","25     0.015625     0.890679  \n","26     0.075469     1.736600  \n","27     0.029190     0.828880  \n","28     0.080243     0.942413  \n","29     0.039755     0.724029  \n","30     0.022199     0.693465  \n","31     0.014942     0.754936  \n","32     0.018270     0.418364  \n","33     0.016093     0.464989  \n","34     0.013285     0.815763  \n","35     0.009253     0.842908  \n","36     0.018828     0.387947  \n","37     0.014753     0.479800  \n","38     0.015405     0.774403  \n","39     0.111856     0.180708  \n","40     0.189900     0.302917  \n","41  1642.116089  2259.958740  \n","42  1271.904419  1495.867432  \n","43  3086.992188  3809.751709  \n","44     0.126516     0.349608  \n","45    13.229795    13.229795  \n","46     5.942063     5.942063  \n","47    12.296374    12.296374  \n","48    13.781157    13.781157  \n","49    16.347080    16.347080  \n","50    30.792080    30.792080  \n","51    15.676671    15.676671  \n","52     0.413523     0.413523  \n","\n","\n","⚠️  警告: 在 Y_new_cleaned 中发现以下可能存在问题的特征! ⚠️\n","     count        mean        std         min         25%         50%  \\\n","0   1794.0 -470.050720  60.315937 -638.181213 -493.909241 -461.944916   \n","2   1794.0    2.162170  13.212750  -35.646679   -5.782913    2.054442   \n","4   1794.0  -13.781521  14.066177  -49.572872  -21.916519  -11.631197   \n","5   1794.0   -4.522140   7.913166  -20.664915  -10.280624   -5.429566   \n","6   1794.0  -15.373235   7.370799  -34.290909  -20.675146  -15.479896   \n","7   1794.0   -8.971362   6.179687  -23.111113  -13.198444   -9.163463   \n","8   1794.0  -13.942215   8.802371  -36.160545  -21.201115  -13.789647   \n","9   1794.0   -6.030565   4.220081  -17.253183   -8.469540   -5.351323   \n","10  1794.0   -9.332506   3.838567  -18.818361  -11.493132   -9.499219   \n","11  1794.0   -1.450368   4.256322  -13.278951   -3.812079   -1.297798   \n","12  1794.0   -7.069556   3.905807  -18.234789   -9.725375   -6.942660   \n","13  1794.0    0.129775   0.769055   -2.561882   -0.195643    0.084362   \n","14  1794.0    0.000840   0.357307   -1.643914   -0.041706    0.011908   \n","15  1794.0    0.025269   0.364041   -1.250387   -0.078744   -0.000823   \n","16  1794.0   -0.038380   0.259550   -1.068002   -0.055086   -0.001948   \n","17  1794.0   -0.008332   0.279220   -0.916198   -0.082592   -0.026915   \n","18  1794.0    0.016527   0.223180   -0.712911   -0.048649   -0.008696   \n","19  1794.0    0.015298   0.202103   -0.585848   -0.071887   -0.030056   \n","20  1794.0   -0.038302   0.271575   -1.362082   -0.066753   -0.018023   \n","21  1794.0   -0.052010   0.210626   -0.765947   -0.102566   -0.031019   \n","22  1794.0    0.011458   0.166565   -0.729821   -0.039525   -0.006947   \n","23  1794.0    0.008911   0.217598   -0.936341   -0.060816   -0.009889   \n","24  1794.0   -0.006182   0.176860   -0.782298   -0.044478   -0.008088   \n","25  1794.0   -0.013713   0.194298   -0.758730   -0.042033   -0.009310   \n","26  1794.0    0.047872   0.265612   -0.985975   -0.028222    0.010255   \n","27  1794.0    0.030021   0.177043   -0.639129   -0.029353   -0.004045   \n","28  1794.0    0.053852   0.199447   -0.634004   -0.014186    0.002991   \n","29  1794.0    0.050817   0.176814   -0.796793   -0.012226    0.004928   \n","30  1794.0    0.025059   0.144418   -0.497829   -0.015684    0.001819   \n","31  1794.0    0.010289   0.146932   -0.493729   -0.011293   -0.000136   \n","32  1794.0    0.008153   0.116870   -0.439982   -0.019341   -0.000438   \n","33  1794.0   -0.000303   0.133611   -0.677725   -0.012912   -0.000281   \n","34  1794.0    0.002418   0.125646   -0.556236   -0.018367   -0.000323   \n","35  1794.0   -0.015927   0.149306   -0.917669   -0.019623   -0.002913   \n","36  1794.0   -0.006140   0.139826   -0.749391   -0.016092   -0.001542   \n","37  1794.0   -0.005879   0.158900   -1.008433   -0.013370   -0.001105   \n","38  1794.0    0.007941   0.176297   -0.947804   -0.012241    0.000188   \n","\n","           75%         max  \n","0  -424.323364 -355.909821  \n","2    11.351695   30.508446  \n","4    -3.513369   14.755736  \n","5     0.372821   13.091414  \n","6   -10.079907    2.650982  \n","7    -4.704797    5.416973  \n","8    -6.990566    7.928951  \n","9    -2.974723    4.608061  \n","10   -6.700928    2.305941  \n","11    0.531184   10.570538  \n","12   -4.599995    2.498079  \n","13    0.765658    1.305332  \n","14    0.121311    1.107511  \n","15    0.074504    2.314250  \n","16    0.038448    1.037140  \n","17    0.028528    1.718484  \n","18    0.033571    1.115180  \n","19    0.012126    0.981687  \n","20    0.014427    1.568107  \n","21    0.012084    1.264772  \n","22    0.028176    0.656098  \n","23    0.015840    1.239675  \n","24    0.016629    0.655183  \n","25    0.015625    0.890679  \n","26    0.075469    1.736600  \n","27    0.029190    0.828880  \n","28    0.080243    0.942413  \n","29    0.039755    0.724029  \n","30    0.022199    0.693465  \n","31    0.014942    0.754936  \n","32    0.018270    0.418364  \n","33    0.016093    0.464989  \n","34    0.013285    0.815763  \n","35    0.009253    0.842908  \n","36    0.018828    0.387947  \n","37    0.014753    0.479800  \n","38    0.015405    0.774403  \n"]}]},{"cell_type":"code","source":["\n","\n","\n","# =============================================================================\n","# 步骤 2: 使用净化后的数据，以一个更简单的模型进行验证\n","# =============================================================================\n","\n","# 1. 划分数据集\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","    X_new, Y_new_cleaned, test_size=0.2, random_state=42 # 使用 Y_new_cleaned\n",")\n","\n","# 2. 对 Y 进行同样的“填充-标准化-PCA”流程\n","imputer_y = SimpleImputer(strategy='mean')\n","scaler_y = StandardScaler()\n","pca_y = PCA(n_components=0.95)\n","\n","Y_train_imputed = imputer_y.fit_transform(Y_train)\n","Y_train_scaled = scaler_y.fit_transform(Y_train_imputed)\n","Y_train_pca = pca_y.fit_transform(Y_train_scaled)\n","\n","Y_test_imputed = imputer_y.transform(Y_test)\n","Y_test_scaled = scaler_y.transform(Y_test_imputed)\n","Y_test_pca = pca_y.transform(Y_test_imputed)\n","print(f\"净化后的 Y 已被提纯至 {pca_y.n_components_} 个主成分。\")\n","\n","\n","# 3. 对 X 进行标准化\n","scaler_x = StandardScaler()\n","X_train_scaled = scaler_x.fit_transform(X_train)\n","X_test_scaled = scaler_x.transform(X_test)\n","\n","\n","# 4. 使用一个更简单、更稳健的随机森林模型进行验证\n","#    我们大大降低了模型的复杂度，以避免其学习到“伪规律”\n","print(\"\\n正在使用一个更稳健的简化模型进行训练...\")\n","robust_rf_model = RandomForestRegressor(\n","    n_estimators=100,       # 树的数量减少\n","    random_state=42,\n","    n_jobs=-1,\n","    max_depth=10,           # 关键：大大降低树的深度！\n","    min_samples_leaf=10,    # 关键：要求每个叶节点有更多样本\n",")\n","\n","robust_rf_model.fit(X_train_scaled, Y_train_pca)\n","print(\"模型训练完成!\")\n","\n","\n","# 5. 评估\n","Y_pred = robust_rf_model.predict(X_test_scaled)\n","R2 = r2_score(Y_test_pca, Y_pred)\n","RMSE = np.sqrt(mean_squared_error(Y_test_pca, Y_pred))\n","\n","print(f\"\\n--- ✨ 数据净化与简化模型验证结果 ✨ ---\")\n","print(f\"R² 分数: {R2:.4f}\")\n","print(f\"均方根误差 (RMSE): {RMSE:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRVotGNSzgIm","executionInfo":{"status":"ok","timestamp":1759238937870,"user_tz":-180,"elapsed":29062,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"0890d0e5-4ba0-44d4-976f-1d174186cd73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["净化前 Y 的形状: (1794, 54)\n","检测到并删除了 1 个完全无效的特征列。\n","净化后 Y 的形状: (1794, 53)\n","净化后的 Y 已被提纯至 25 个主成分。\n","\n","正在使用一个更稳健的简化模型进行训练...\n","模型训练完成!\n","\n","--- ✨ 数据净化与简化模型验证结果 ✨ ---\n","R² 分数: -31.7470\n","均方根误差 (RMSE): 563.4248\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IVNTblaJ0m8Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"gMXCAsmWl6hR"}}]}