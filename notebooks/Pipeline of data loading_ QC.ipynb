{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1R6MuYJ3JDcU-O9uo3VbillQMtaVVrGRI","authorship_tag":"ABX9TyMvHLf5O2oY/lOuoSTs37Uc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JOzghjzdqN9X","executionInfo":{"status":"ok","timestamp":1760432154002,"user_tz":-180,"elapsed":2158,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"outputs":[],"source":["# ===============================================\n","# EEG × Sound 全流程分析管线（Colab 一键运行版）\n","# 覆盖：加载→QC→声学特征修复→噪声上限→时延→通道ROI→被试级TRF\n","# 依赖：numpy, tqdm, scikit-learn（Colab自带；若报错可取消下一行注释）\n","# !pip install -q numpy tqdm scikit-learn\n","# ===============================================\n","import os, glob, json, math, csv\n","import numpy as np\n","from tqdm import tqdm\n","from collections import defaultdict, Counter\n","from sklearn.model_selection import GroupKFold\n","\n","\n"]},{"cell_type":"code","source":["!pip -q install librosa soundfile"],"metadata":{"id":"4qRm584DUxU2","executionInfo":{"status":"ok","timestamp":1760432158193,"user_tz":-180,"elapsed":4187,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 0) 数据加载（与你之前一致）\n","# -----------------------------\n","def load_segments_with_subject_ids(root_dir, eeg_suffix='EEG_aligned.npy', sound_suffix='Sound_aligned.npy', root_suffix='feature_normalized'):\n","    eeg_segments_list = []\n","    sound_segments_list = []\n","    subject_ids_list = []\n","\n","    print(f\"开始从根目录 '{root_dir}' 加载数据段及被试者ID...\")\n","    subject_folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n","\n","    for subject in tqdm(subject_folders, desc=\"处理被试者\"):\n","        subject_path = os.path.join(root_dir, subject, root_suffix)\n","        eeg_files = glob.glob(os.path.join(subject_path, f'*{eeg_suffix}'))\n","        for eeg_file_path in eeg_files:\n","            base_name = os.path.basename(eeg_file_path).replace(eeg_suffix, '')\n","            sound_file_path = os.path.join(subject_path, base_name + sound_suffix)\n","            if os.path.exists(sound_file_path):\n","                try:\n","                    eeg_segment = np.load(eeg_file_path)\n","                    sound_segment = np.load(sound_file_path)\n","                    if eeg_segment.shape[0] == sound_segment.shape[0]:\n","                        eeg_segments_list.append(eeg_segment)\n","                        sound_segments_list.append(sound_segment)\n","                        subject_ids_list.append(subject)\n","                except Exception as e:\n","                    print(f\"加载文件 {os.path.basename(eeg_file_path)} 时出错: {e}\")\n","\n","    print(f\"\\n加载完成！总共加载了 {len(eeg_segments_list)} 个数据段。\")\n","    return eeg_segments_list, sound_segments_list, subject_ids_list"],"metadata":{"id":"5Lj5UXGoqrbt","executionInfo":{"status":"ok","timestamp":1760432158209,"user_tz":-180,"elapsed":3,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 1) 基础 QC / 预处理工具\n","# -----------------------------\n","def filter_and_summarize(eegs, snds, sids, min_frames=20):\n","    kept_e, kept_s, kept_id = [], [], []\n","    n_emptyT, n_emptyD, n_short = 0, 0, 0\n","    for E, S, sid in zip(eegs, snds, sids):\n","        if E.ndim != 2 or S.ndim != 2:\n","            n_emptyD += 1; continue\n","        T1, D1 = E.shape; T2, D2 = S.shape\n","        if T1 == 0 or T2 == 0:\n","            n_emptyT += 1; continue\n","        if D1 == 0 or D2 == 0:\n","            n_emptyD += 1; continue\n","        if T1 < min_frames or T2 < min_frames:\n","            n_short += 1; continue\n","        kept_e.append(E); kept_s.append(S); kept_id.append(sid)\n","    print(f\"过滤结果：总 {len(eegs)} 段 -> 保留 {len(kept_e)} 段 | 空T: {n_emptyT}, 空D: {n_emptyD}, 过短(<{min_frames}帧): {n_short}\")\n","    return kept_e, kept_s, kept_id\n","\n","def nan_inf_report(eegs, snds):\n","    def stats(arrs, name):\n","        n = len(arrs)\n","        any_nan = sum([np.isnan(a).any() for a in arrs])\n","        any_inf = sum([np.isinf(a).any() for a in arrs])\n","        print(f\"{name}: 段数={n}, 含NaN段={any_nan} ({any_nan/n:.1%}), 含Inf段={any_inf} ({any_inf/n:.1%})\")\n","    stats(eegs, \"EEG\"); stats(snds, \"Sound\")\n","\n","def nan_breakdown_per_segment(S):\n","    S = np.asarray(S)\n","    nan_mask = ~np.isfinite(S)\n","    overall = nan_mask.mean() if S.size else 1.0\n","    per_col = nan_mask.mean(axis=0) if S.ndim==2 and S.shape[1]>0 else np.array([])\n","    return overall, per_col\n","\n","def summarize_sound_nan(sound_segments):\n","    overall_rates = []\n","    percol_accum_sum = None\n","    percol_accum_cnt = None\n","    D_max = max(s.shape[1] for s in sound_segments if s.ndim==2) if sound_segments else 0\n","    for S in sound_segments:\n","        overall, per_col = nan_breakdown_per_segment(S)\n","        overall_rates.append(overall)\n","        if per_col.size:\n","            if percol_accum_sum is None:\n","                percol_accum_sum = np.zeros(D_max, dtype=float)\n","                percol_accum_cnt = np.zeros(D_max, dtype=float)\n","            d = per_col.size\n","            percol_accum_sum[:d] += per_col\n","            percol_accum_cnt[:d] += 1.0\n","    print(\"\\n=== 声音特征 NaN 概览 ===\")\n","    print(f\"- 段级：含NaN的段 = {sum(r>0 for r in overall_rates)}/{len(overall_rates)} ({sum(r>0 for r in overall_rates)/len(overall_rates):.1%}); 中位数NaN率 = {np.median(overall_rates):.2%}\")\n","    if percol_accum_cnt is not None:\n","        percol_mean = percol_accum_sum / np.maximum(percol_accum_cnt, 1e-9)\n","        top_bad = np.argsort(-percol_mean)[:10]\n","        print(f\"- 列级（跨段平均）前10个最差列及其NaN率：\")\n","        for j in top_bad:\n","            print(f\"  列{j}: 平均NaN率={percol_mean[j]:.2%}\")\n","        return percol_mean\n","    else:\n","        return None"],"metadata":{"id":"swLw_Sfjqopd","executionInfo":{"status":"ok","timestamp":1760432158230,"user_tz":-180,"elapsed":19,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 2) 声音特征修复（丢列+插值+z-score）\n","# -----------------------------\n","def interp_nan_1d(x):\n","    x = np.asarray(x, dtype=np.float64)\n","    n = len(x)\n","    if n == 0: return x\n","    idx = np.arange(n)\n","    m = np.isfinite(x)\n","    if m.sum() == 0:\n","        return np.zeros_like(x)\n","    y = x.copy()\n","    y[~m] = np.interp(idx[~m], idx[m], x[m])\n","    return y\n","\n","def repair_sound_matrix(S, drop_thr=0.6):\n","    S = np.asarray(S, dtype=np.float64)\n","    T, D = S.shape\n","    col_nan_rate = np.mean(~np.isfinite(S), axis=0)\n","    keep_mask = col_nan_rate <= drop_thr\n","    if keep_mask.sum() == 0:\n","        return np.zeros((T,0), dtype=np.float64), keep_mask\n","    S2 = S[:, keep_mask].copy()\n","    for d in range(S2.shape[1]):\n","        S2[:, d] = interp_nan_1d(S2[:, d])\n","    mu = S2.mean(axis=0, keepdims=True)\n","    sd = S2.std(axis=0, keepdims=True); sd[sd==0] = 1.0\n","    S2 = (S2 - mu) / sd\n","    return S2, keep_mask\n","\n","def batch_repair_sound(sound_segments, drop_thr=0.6):\n","    repaired = []\n","    dropped_cols_stat = []\n","    for S in tqdm(sound_segments, desc=\"修复声音特征\"):\n","        S2, keep_mask = repair_sound_matrix(S, drop_thr=drop_thr)\n","        repaired.append(S2)\n","        dropped_cols_stat.append({\"D_in\": S.shape[1], \"D_kept\": int(keep_mask.sum())})\n","    print(\"修复完成：平均保留列数 =\",\n","          np.mean([r[\"D_kept\"] for r in dropped_cols_stat]),\n","          \" / 平均原始列数 =\",\n","          np.mean([r[\"D_in\"] for r in dropped_cols_stat]))\n","    return repaired, dropped_cols_stat"],"metadata":{"id":"Nkz6oLSlqmRf","executionInfo":{"status":"ok","timestamp":1760432158237,"user_tz":-180,"elapsed":5,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 3) 信号处理 & 互相关工具\n","# -----------------------------\n","def zscore1d(x):\n","    x = np.asarray(x, dtype=np.float64)\n","    m, s = x.mean(), x.std()\n","    return (x - m)/(s if s>0 and np.isfinite(s) else 1.0), m, (s if s>0 and np.isfinite(s) else 1.0)\n","\n","def highpass_moving_average(ts, win=15):\n","    ts = np.asarray(ts, dtype=np.float64)\n","    if ts.size == 0: return ts\n","    if ts.size < 2*win:\n","        return (ts - ts.mean())/(ts.std() if ts.std()>0 else 1.0)\n","    kernel = np.ones(win, dtype=np.float64)/win\n","    trend = np.convolve(ts, kernel, mode='same')\n","    hp = ts - trend\n","    return (hp - hp.mean())/(hp.std() if hp.std()>0 else 1.0)\n","\n","def first_pc_time_series(X):\n","    X = np.asarray(X, dtype=np.float64)\n","    if X.size == 0 or min(X.shape) < 2:\n","        return np.array([])\n","    U,S,VT = np.linalg.svd((X - X.mean(0)) / (X.std(0) + 1e-12), full_matrices=False)\n","    return (U[:,0]*S[0]).astype(np.float64)\n","\n","def envelope_from_matrix(S):\n","    if S.size == 0: return np.array([])\n","    e = np.sqrt((S**2).sum(axis=1))\n","    return (e - e.mean())/(e.std() if e.std()>0 else 1.0)\n","\n","def causal_ma(ts, win=9):\n","    ts = np.asarray(ts, dtype=np.float64)\n","    if ts.size==0: return ts\n","    out = np.empty_like(ts); csum = 0.0\n","    for i in range(len(ts)):\n","        csum += ts[i]\n","        if i >= win: csum -= ts[i-win]\n","        out[i] = csum / min(i+1, win)\n","    return (out - out.mean())/(out.std() if out.std()>0 else 1.0)\n","\n","def normxcorr_1d(x, y, max_lag, min_eff=12):\n","    x = np.asarray(x, dtype=np.float64); y = np.asarray(y, dtype=np.float64)\n","    T = min(len(x), len(y)); x, y = x[:T], y[:T]\n","    if T < max(min_eff + 1, max_lag + 2): return np.array([]), np.array([])\n","    x = (x - x.mean())/(x.std() if x.std()>0 else 1.0)\n","    y = (y - y.mean())/(y.std() if y.std()>0 else 1.0)\n","    lags = np.arange(-max_lag, max_lag+1, dtype=int)\n","    cs = []\n","    for lag in lags:\n","        if lag>=0: xx, yy = x[lag:], y[:T-lag]\n","        else:      xx, yy = x[:T+lag], y[-lag:]\n","        if len(xx) < min_eff or len(yy) < min_eff: cs.append(np.nan); continue\n","        sx, sy = xx.std(), yy.std()\n","        if sx==0 or sy==0 or not np.isfinite(sx) or not np.isfinite(sy): cs.append(np.nan); continue\n","        cs.append(np.corrcoef(xx, yy)[0,1])\n","    return lags, np.array(cs, dtype=np.float64)\n","\n","def _summarize_lag_rows(rows):\n","    def med(key):\n","        vals = [r[key] for r in rows if np.isfinite(r.get(key, np.nan))]\n","        return float(np.median(vals)) if vals else np.nan\n","    frac = np.mean([\n","        (r.get(\"peak_r\", np.nan) > r.get(\"peak_r_null\", np.nan))\n","        for r in rows\n","        if np.isfinite(r.get(\"peak_r\", np.nan)) and np.isfinite(r.get(\"peak_r_null\", np.nan))\n","    ]) if any(np.isfinite(r.get(\"peak_r\", np.nan)) and np.isfinite(r.get(\"peak_r_null\", np.nan)) for r in rows) else np.nan\n","    return {\n","        \"median_peak_r\": med(\"peak_r\"),\n","        \"median_peak_lag_ms\": med(\"peak_lag_ms\"),\n","        \"median_peak_r_null\": med(\"peak_r_null\"),\n","        \"frac_r_gt_null\": float(frac) if np.isfinite(frac) else np.nan\n","    }"],"metadata":{"id":"uqEV3c66qk-a","executionInfo":{"status":"ok","timestamp":1760432158258,"user_tz":-180,"elapsed":12,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# -----------------------------\n","# 4) 噪声上限（基于PC1的分块split-half）\n","# -----------------------------\n","def split_half_1d(ts, block_len=20):\n","    ts = np.asarray(ts, dtype=np.float64)\n","    if ts.size < block_len*2: return np.nan\n","    # 分块均值\n","    n_blocks = len(ts)//block_len\n","    B = ts[:n_blocks*block_len].reshape(n_blocks, block_len).mean(axis=1)\n","    x, y = B[0::2], B[1::2]\n","    if len(x)<3 or len(y)<3: return np.nan\n","    r_half = np.corrcoef((x-x.mean())/(x.std() or 1.0), (y-y.mean())/(y.std() or 1.0))[0,1]\n","    if not np.isfinite(r_half): return np.nan\n","    return (2*r_half)/(1+r_half)\n","\n","def fisher_mean(rs):\n","    rs = [r for r in rs if np.isfinite(r)]\n","    if not rs: return np.nan\n","    z = np.arctanh(np.clip(rs, -0.999999, 0.999999))\n","    return float(np.tanh(np.mean(z)))\n","\n","def noise_ceiling_from_pc1(eeg_segments, sound_repaired):\n","    eeg_r_blk, snd_r_blk = [], []\n","    for E, S2 in zip(eeg_segments, sound_repaired):\n","        eeg_pc1 = first_pc_time_series(E)\n","        snd_pc1 = first_pc_time_series(S2) if S2.size else np.array([])\n","        eeg_r_blk.append(split_half_1d(eeg_pc1, block_len=20))\n","        snd_r_blk.append(split_half_1d(snd_pc1, block_len=20))\n","    r_eeg = fisher_mean(eeg_r_blk)\n","    r_snd = fisher_mean(snd_r_blk)\n","    r_max = np.sqrt(r_eeg*r_snd) if (np.isfinite(r_eeg) and np.isfinite(r_snd) and r_eeg>0 and r_snd>0) else np.nan\n","    print(\"\\n=== 基于 PC1 的分块噪声上限 ===\")\n","    print(json.dumps({\"r_eeg_blk_overall_PC1\": r_eeg, \"r_sound_blk_overall_PC1\": r_snd, \"r_max_blk_overall_PC1\": r_max},\n","                     ensure_ascii=False, indent=2))\n","    return r_eeg, r_snd, r_max\n"],"metadata":{"id":"j66Lbupeqj1U","executionInfo":{"status":"ok","timestamp":1760432158277,"user_tz":-180,"elapsed":9,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 5) 时延：PC1↔PC1 与 PC1↔Envelope\n","# -----------------------------\n","def compute_lag_stats(eeg_segments, sound_repaired, frame_ms=11.0, max_lag_ms=300):\n","    max_lag = int(round(max_lag_ms/frame_ms))\n","    rows_pc1, rows_env = [], []\n","    for E, S2 in tqdm(list(zip(eeg_segments, sound_repaired)), desc=\"Lag PC1 / Envelope\"):\n","        eeg_pc1 = first_pc_time_series(E)\n","        snd_pc1 = first_pc_time_series(S2) if S2.size else np.array([])\n","        env_ts  = envelope_from_matrix(S2) if S2.size else np.array([])\n","        # PC1↔PC1\n","        lags, cs = normxcorr_1d(eeg_pc1, snd_pc1, max_lag)\n","        if lags.size and np.any(np.isfinite(cs)):\n","            i = int(np.nanargmax(cs)); peak_r, lag_ms = float(cs[i]), float(lags[i]*frame_ms)\n","            # null\n","            sh = max(1, int(round(len(snd_pc1)*0.33))) if len(snd_pc1) else 1\n","            snd_sh = np.roll(snd_pc1, sh) if len(snd_pc1) else snd_pc1\n","            _, cs0 = normxcorr_1d(eeg_pc1, snd_sh, max_lag)\n","            peak_r_null = float(np.nanmax(cs0)) if np.any(np.isfinite(cs0)) else np.nan\n","        else:\n","            peak_r, lag_ms, peak_r_null = np.nan, np.nan, np.nan\n","        rows_pc1.append({\"peak_r\": peak_r, \"peak_lag_ms\": lag_ms, \"peak_r_null\": peak_r_null})\n","        # PC1↔Envelope\n","        lags, cs = normxcorr_1d(eeg_pc1, env_ts, max_lag)\n","        if lags.size and np.any(np.isfinite(cs)):\n","            i = int(np.nanargmax(cs)); peak_r, lag_ms = float(cs[i]), float(lags[i]*frame_ms)\n","            sh = max(1, int(round(len(env_ts)*0.33))) if len(env_ts) else 1\n","            env_sh = np.roll(env_ts, sh) if len(env_ts) else env_ts\n","            _, cs0 = normxcorr_1d(eeg_pc1, env_sh, max_lag)\n","            peak_r_null = float(np.nanmax(cs0)) if np.any(np.isfinite(cs0)) else np.nan\n","        else:\n","            peak_r, lag_ms, peak_r_null = np.nan, np.nan, np.nan\n","        rows_env.append({\"peak_r\": peak_r, \"peak_lag_ms\": lag_ms, \"peak_r_null\": peak_r_null})\n","    print(\"\\n=== 时延（PC1↔PC1）汇总 ===\"); print(json.dumps(_summarize_lag_rows(rows_pc1), ensure_ascii=False, indent=2))\n","    print(\"\\n=== 时延（PC1↔Envelope）汇总 ===\"); print(json.dumps(_summarize_lag_rows(rows_env), ensure_ascii=False, indent=2))\n","    return rows_pc1, rows_env"],"metadata":{"id":"M4zwwp8zqiCi","executionInfo":{"status":"ok","timestamp":1760432158332,"user_tz":-180,"elapsed":50,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 6) 通道级 ROI（逐段最佳通道 + 汇总）\n","# -----------------------------\n","def voiced_mask_from_original(S_orig, voicing_cols, fallback_percentile=40):\n","    T, D = S_orig.shape\n","    if len(voicing_cols):\n","        vc = [c for c in voicing_cols if c < D]\n","        if len(vc):\n","            m = np.any(np.isfinite(S_orig[:, vc]), axis=1)\n","            if m.any():\n","                return m.astype(bool)\n","    e = np.sqrt((np.nan_to_num(S_orig)**2).sum(axis=1))\n","    thr = np.percentile(e[~np.isnan(e)], fallback_percentile) if np.any(~np.isnan(e)) else 0.0\n","    return (e > thr)\n","\n","def compute_lag_stats_channelwise(eeg_segments, sound_segments, sound_repaired, *,\n","                                  frame_ms=11.0, max_lag_ms=300, null_shift_ratio=0.33, voicing_cols=None):\n","    max_lag = int(round(max_lag_ms / frame_ms))\n","    per_seg = []; ch_counter = Counter()\n","    for E, S_orig, S_rep in tqdm(list(zip(eeg_segments, sound_segments, sound_repaired)), desc=\"Channelwise ROI\"):\n","        vm = voiced_mask_from_original(S_orig, voicing_cols or [], 40)\n","        env = envelope_from_matrix(S_rep)\n","        env = (env - env.mean())/(env.std() if env.std()>0 else 1.0)\n","        best = {\"peak_r\": np.nan, \"peak_lag_ms\": np.nan, \"peak_r_null\": np.nan, \"best_ch\": -1}\n","        for ch in range(E.shape[1]):\n","            y = (E[:,ch]-E[:,ch].mean())/(E[:,ch].std() if E[:,ch].std()>0 else 1.0)\n","            y = highpass_moving_average(y, 15)\n","            mlen = min(len(y), len(env), len(vm))\n","            if mlen < 30: continue\n","            yy, ee, mm = y[:mlen], env[:mlen], vm[:mlen]\n","            lags, cs = normxcorr_1d(yy[mm], ee[mm], max_lag)\n","            if cs.size==0 or np.all(~np.isfinite(cs)): continue\n","            i = int(np.nanargmax(cs)); r, lag_ms = float(cs[i]), float(lags[i]*frame_ms)\n","            # null\n","            shift = max(1, int(round(len(ee)*null_shift_ratio)))\n","            eesh = np.roll(ee, shift)\n","            _, csn = normxcorr_1d(yy[mm], eesh[mm], max_lag)\n","            rnull = float(np.nanmax(csn)) if np.any(np.isfinite(csn)) else np.nan\n","            if not np.isfinite(best[\"peak_r\"]) or r > best[\"peak_r\"]:\n","                best = {\"peak_r\": r, \"peak_lag_ms\": lag_ms, \"peak_r_null\": rnull, \"best_ch\": ch}\n","        per_seg.append(best)\n","        if best[\"best_ch\"] >= 0:\n","            ch_counter[best[\"best_ch\"]] += 1\n","    overall = _summarize_lag_rows(per_seg); overall[\"top_channels\"] = ch_counter.most_common(10)\n","    print(\"\\n=== 通道级 ROI 汇总 ===\"); print(json.dumps(overall, ensure_ascii=False, indent=2))\n","    return {\"per_segment\": per_seg, \"overall_summary\": overall}\n","\n","\n"],"metadata":{"id":"bk9doYH4qhIz","executionInfo":{"status":"ok","timestamp":1760432158357,"user_tz":-180,"elapsed":2,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 7) TRF（0..200ms，ROI-in-train + 列标准化 + 二阶差分平滑 + 嵌套CV）\n","# -----------------------------\n","def build_lagged_design(env, lags_fr, voicing=None):\n","    T = len(env); X = np.zeros((T, len(lags_fr)), dtype=np.float64)\n","    for i,L in enumerate(lags_fr):\n","        if L>=0: X[L:, i] = env[:T-L]\n","        else:    X[:T+L, i] = env[-L:]\n","    if voicing is None:\n","        return X\n","    v = np.asarray(voicing, dtype=np.float64).reshape(-1,1)\n","    v = v[:T]\n","    return np.hstack([X[:T], v])\n","\n","def diff2_mat(L):\n","    if L < 3: return np.zeros((L, L), dtype=np.float64)\n","    D = np.zeros((L-2, L), dtype=np.float64)\n","    for i in range(L-2):\n","        D[i, i]   = 1.0\n","        D[i, i+1] = -2.0\n","        D[i, i+2] = 1.0\n","    return D.T @ D\n","\n","def trf_fit_ridge_smooth(X_tr, y_tr, alpha=10.0, beta=10.0, n_lag_cols=None, alpha_voicing=None):\n","    N, P = X_tr.shape\n","    L = int(n_lag_cols if n_lag_cols is not None else P-1)\n","    XtX = X_tr.T @ X_tr\n","    XtY = X_tr.T @ y_tr\n","    A = XtX + alpha * np.eye(P)\n","    if beta > 0 and L >= 3:\n","        D2 = diff2_mat(L)\n","        A[:L, :L] += beta * D2\n","    if alpha_voicing is not None and P > L:\n","        A[L, L] += (alpha_voicing - alpha)\n","    w = np.linalg.solve(A, XtY)\n","    return w\n","\n","def fit_standardizer(X):\n","    mu = X.mean(axis=0); sd = X.std(axis=0)\n","    sd[(~np.isfinite(sd)) | (sd==0)] = 1.0\n","    return mu, sd\n","\n","def apply_standardizer(X, mu, sd):\n","    return (X - mu) / sd\n","\n","def select_roi_channels_for_subject(eeg_segments, sound_segments, sound_repaired, train_idx, top_k=3, frame_ms=11.0, max_lag_ms=200, voicing_cols=None):\n","    max_lag = int(round(max_lag_ms/frame_ms))\n","    D = eeg_segments[train_idx[0]].shape[1]\n","    per_ch_rs = [[] for _ in range(D)]\n","    for i in train_idx:\n","        E = eeg_segments[i]; S0 = sound_segments[i]; Sr = sound_repaired[i]\n","        vm = voiced_mask_from_original(S0, voicing_cols or [], 40)\n","        env = causal_ma(envelope_from_matrix(Sr), win=9)\n","        yenv = (env - env.mean())/(env.std() if env.std()>0 else 1.0)\n","        for ch in range(D):\n","            y = (E[:,ch]-E[:,ch].mean())/(E[:,ch].std() if E[:,ch].std()>0 else 1.0)\n","            y = highpass_moving_average(y, 15)\n","            mlen = min(len(y), len(yenv), len(vm))\n","            lags, cs = normxcorr_1d(y[:mlen][vm[:mlen]], yenv[:mlen][vm[:mlen]], max_lag)\n","            if cs.size and np.any(np.isfinite(cs)):\n","                per_ch_rs[ch].append(float(np.nanmax(cs)))\n","    ch_scores = np.array([np.median(rs) if len(rs) else -np.inf for rs in per_ch_rs])\n","    roi = np.argsort(-ch_scores)[:top_k]\n","    return roi.tolist()\n","\n","def eval_subject_trf(subject_id, eeg_segments, sound_segments, sound_repaired, subject_ids, voicing_cols, frame_ms=11.0):\n","    idx = [i for i, sid in enumerate(subject_ids) if sid == subject_id]\n","    n_segs = len(idx)\n","    if n_segs < 8:\n","        return {\"subject\": subject_id, \"note\": \"too few segments\"}\n","    groups = np.arange(n_segs)\n","    outer = GroupKFold(n_splits=min(5, n_segs))\n","    lags_ms = np.arange(0, 201, 11)\n","    lags_fr = (lags_ms / frame_ms).astype(int)\n","    L = len(lags_fr)\n","    alpha_grid = [1.0, 10.0, 100.0]\n","    beta_grid  = [0.0, 10.0, 100.0]\n","    seg_corrs, seg_corrs_null, peak_lags = [], [], []\n","\n","    for tr_idx_rel, va_idx_rel in outer.split(np.zeros(n_segs), groups=groups):\n","        tr_idx = [idx[i] for i in tr_idx_rel]\n","        va_idx = [idx[i] for i in va_idx_rel]\n","        roi = select_roi_channels_for_subject(eeg_segments, sound_segments, sound_repaired, tr_idx,\n","                                              top_k=3, frame_ms=frame_ms, max_lag_ms=200, voicing_cols=voicing_cols)\n","        def build_dataset(seg_indices):\n","            X_list, y_list = [], []\n","            for k in seg_indices:\n","                E = eeg_segments[k]; S0 = sound_segments[k]; Sr = sound_repaired[k]\n","                env = causal_ma(envelope_from_matrix(Sr), win=9)\n","                vm  = voiced_mask_from_original(S0, voicing_cols or [], 40)\n","                Xseg = build_lagged_design(env, lags_fr, voicing=vm)\n","                ychs = []\n","                for ch in roi:\n","                    y = (E[:,ch]-E[:,ch].mean())/(E[:,ch].std() if E[:,ch].std()>0 else 1.0)\n","                    y = highpass_moving_average(y, 15)\n","                    ychs.append(y[:Xseg.shape[0]])\n","                yseg = np.mean(np.vstack(ychs), axis=0) if len(ychs) else np.zeros(Xseg.shape[0])\n","                T = min(Xseg.shape[0], len(yseg))\n","                X_list.append(Xseg[:T]); y_list.append(yseg[:T])\n","            X = np.vstack(X_list); y = np.concatenate(y_list)\n","            return X, y\n","\n","        Xtr_raw, ytr_raw = build_dataset(tr_idx)\n","        Xva_raw_list, yva_raw_list = [], []\n","        for k in va_idx:\n","            Xk, yk = build_dataset([k])\n","            Xva_raw_list.append(Xk); yva_raw_list.append(yk)\n","\n","        Xmu, Xsd = fit_standardizer(Xtr_raw); Xtr = apply_standardizer(Xtr_raw, Xmu, Xsd)\n","        ytr, ymu, ysd = zscore1d(ytr_raw)\n","        n = len(ytr); ntr = int(0.8*n)\n","        Xtr_i, ytr_i = Xtr[:ntr], ytr[:ntr]\n","        Xvl_i, yvl_i = Xtr[ntr:], ytr[ntr:]\n","        best_score, best_hp = -np.inf, (10.0, 10.0)\n","        for alpha in alpha_grid:\n","            for beta in beta_grid:\n","                w = trf_fit_ridge_smooth(Xtr_i, ytr_i, alpha=alpha, beta=beta, n_lag_cols=L, alpha_voicing=alpha)\n","                yhat = Xvl_i @ w\n","                r = np.corrcoef(yvl_i, yhat)[0,1] if yvl_i.std()>0 and yhat.std()>0 else -np.inf\n","                if np.isfinite(r) and r > best_score:\n","                    best_score, best_hp = r, (alpha, beta)\n","        alpha, beta = best_hp\n","        w = trf_fit_ridge_smooth(Xtr, ytr, alpha=alpha, beta=beta, n_lag_cols=L, alpha_voicing=alpha)\n","        lag_block = w[:L]\n","        pk = int(np.argmax(np.abs(lag_block))) if L else 0\n","        peak_lags.append(float(pk * 11.0))\n","        for Xk_raw, yk_raw in zip(Xva_raw_list, yva_raw_list):\n","            Xk = apply_standardizer(Xk_raw, Xmu, Xsd)\n","            yk = (yk_raw - ymu) / (ysd if ysd>0 else 1.0)\n","            yhat = Xk @ w\n","            rk = np.corrcoef(yk, yhat)[0,1] if yk.std()>0 and yhat.std()>0 else np.nan\n","            shift = max(1, int(0.33*len(yk)))\n","            yperm = np.roll(yk, shift)\n","            yhat0 = Xk @ w\n","            rk0 = np.corrcoef(yperm, yhat0)[0,1] if yperm.std()>0 and yhat0.std()>0 else np.nan\n","            seg_corrs.append(rk); seg_corrs_null.append(rk0)\n","\n","    seg_corrs = np.array(seg_corrs, dtype=np.float64)\n","    seg_corrs_null = np.array(seg_corrs_null, dtype=np.float64)\n","    valid = np.isfinite(seg_corrs) & np.isfinite(seg_corrs_null)\n","    res = {\n","        \"subject\": subject_id,\n","        \"n_segments_eval\": int(valid.sum()),\n","        \"median_pred_r\": float(np.median(seg_corrs[valid])) if valid.any() else np.nan,\n","        \"median_pred_r_null\": float(np.median(seg_corrs_null[valid])) if valid.any() else np.nan,\n","        \"frac_r_better_than_null\": float(np.mean(seg_corrs[valid] > seg_corrs_null[valid])) if valid.any() else np.nan,\n","        \"median_trf_peak_ms_(>=0)\": float(np.median(peak_lags)) if len(peak_lags) else np.nan,\n","        \"note\": \"ROI top-3 | lags 0..200ms | ridge + 2nd-diff smoothing\"\n","    }\n","    return res\n","\n","def run_trf_analysis_per_subject(eeg_segments, sound_segments, sound_repaired, subject_ids, *,\n","                                 voicing_cols, frame_ms=11.0):\n","    subjects = sorted(set(subject_ids))\n","    per_subject = [eval_subject_trf(sid, eeg_segments, sound_segments, sound_repaired, subject_ids, voicing_cols, frame_ms=frame_ms) for sid in tqdm(subjects, desc=\"TRF per subject\")]\n","    vals = [r for r in per_subject if np.isfinite(r.get(\"median_pred_r\", np.nan)) and np.isfinite(r.get(\"median_pred_r_null\", np.nan))]\n","    if vals:\n","        med_r  = float(np.median([r[\"median_pred_r\"] for r in vals]))\n","        med_r0 = float(np.median([r[\"median_pred_r_null\"] for r in vals]))\n","        frac   = float(np.mean([r[\"median_pred_r\"] > r[\"median_pred_r_null\"] for r in vals]))\n","        med_pk = float(np.median([r[\"median_trf_peak_ms_(>=0)\"] for r in vals if np.isfinite(r[\"median_trf_peak_ms_(>=0)\"])])) if any(np.isfinite(r[\"median_trf_peak_ms_(>=0)\"]) for r in vals) else np.nan\n","        overall = {\"median_of_subject_medians\": med_r, \"median_of_subject_nulls\": med_r0,\n","                   \"frac_subjects_better_than_null\": frac, \"median_TRF_peak_ms_(>=0)\": med_pk}\n","    else:\n","        overall = {\"median_of_subject_medians\": np.nan, \"median_of_subject_nulls\": np.nan,\n","                   \"frac_subjects_better_than_null\": np.nan, \"median_TRF_peak_ms_(>=0)\": np.nan}\n","    print(\"\\n=== TRF（总体）===\"); print(json.dumps(overall, ensure_ascii=False, indent=2))\n","    return {\"per_subject\": per_subject, \"overall_summary\": overall}\n"],"metadata":{"id":"U_2o0Qp8qfqM","executionInfo":{"status":"ok","timestamp":1760432158402,"user_tz":-180,"elapsed":44,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# -----------------------------\n","# 8) 总管线（可选落盘）\n","# -----------------------------\n","def analyze_eeg_sound_data(root_dir, frame_ms=11.0, max_lag_ms=300, null_shift_ratio=0.33, min_frames=20, drop_thr=0.6, save_dir=None):\n","    \"\"\"\n","    返回字典：\n","      - noise_ceiling_pc1\n","      - lag_alignment {\"pc1\":..., \"envelope\":...}\n","      - channel_roi_summary\n","      - trf_results_per_subject\n","      - sound_nan_summary\n","      - sound_repair_stats\n","    \"\"\"\n","    print(\"\\n--- 开始数据分析管线 ---\")\n","    eegs, snds, sids = load_segments_with_subject_ids(root_dir)\n","    eegs, snds, sids = filter_and_summarize(eegs, snds, sids, min_frames=min_frames)\n","    nan_inf_report(eegs, snds)\n","    percol_nan_mean = summarize_sound_nan(snds)\n","    if percol_nan_mean is None:\n","        Dmax = max(S.shape[1] for S in snds)\n","        percol_nan_mean = np.zeros(Dmax)\n","    snds_rep, drop_stats = batch_repair_sound(snds, drop_thr=drop_thr)\n","    r_eeg_blk, r_snd_blk, r_max_blk = noise_ceiling_from_pc1(eegs, snds_rep)\n","    rows_pc1, rows_env = compute_lag_stats(eegs, snds_rep, frame_ms=frame_ms, max_lag_ms=max_lag_ms)\n","    lag_alignment = {\"pc1\": _summarize_lag_rows(rows_pc1), \"envelope\": _summarize_lag_rows(rows_env)}\n","    voicing_cols = np.where(percol_nan_mean > 0.95)[0].tolist()\n","    ch_roi = compute_lag_stats_channelwise(eegs, snds, snds_rep, frame_ms=frame_ms, max_lag_ms=max_lag_ms,\n","                                           null_shift_ratio=null_shift_ratio, voicing_cols=voicing_cols)\n","    trf_res = run_trf_analysis_per_subject(eegs, snds, snds_rep, sids, voicing_cols=voicing_cols, frame_ms=frame_ms)\n","    per_segment_nan_rates = [float(nan_breakdown_per_segment(S)[0]) for S in snds]\n","\n","    results = {\n","        \"noise_ceiling_pc1\": {\"r_eeg_blk_overall_PC1\": r_eeg_blk, \"r_sound_blk_overall_PC1\": r_snd_blk, \"r_max_blk_overall_PC1\": r_max_blk},\n","        \"lag_alignment\": lag_alignment,\n","        \"channel_roi_summary\": ch_roi,\n","        \"trf_results_per_subject\": trf_res,\n","        \"sound_nan_summary\": {\"per_segment_rates\": per_segment_nan_rates, \"per_col_mean\": percol_nan_mean.tolist()},\n","        \"sound_repair_stats\": drop_stats\n","    }\n","\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","        # JSON 汇总\n","        with open(os.path.join(save_dir, \"summary.json\"), \"w\") as f:\n","            json.dump(results, f, ensure_ascii=False, indent=2)\n","        # 逐段 ROI\n","        with open(os.path.join(save_dir, \"channel_roi_per_segment.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.DictWriter(f, fieldnames=[\"peak_r\",\"peak_lag_ms\",\"peak_r_null\",\"best_ch\"])\n","            w.writeheader(); w.writerows(ch_roi[\"per_segment\"])\n","        # 被试级 TRF\n","        with open(os.path.join(save_dir, \"trf_per_subject.json\"), \"w\") as f:\n","            json.dump(trf_res[\"per_subject\"], f, ensure_ascii=False, indent=2)\n","        # 声学列修复统计\n","        with open(os.path.join(save_dir, \"sound_repair_stats.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.DictWriter(f, fieldnames=[\"D_in\",\"D_kept\"])\n","            w.writeheader(); w.writerows(drop_stats)\n","        # 段级NaN率\n","        with open(os.path.join(save_dir, \"sound_nan_rate_per_segment.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.writer(f); w.writerow([\"nan_rate\"]); w.writerows([[x] for x in per_segment_nan_rates])\n","        print(f\"结果已保存到: {save_dir}\")\n","\n","    print(\"--- 数据分析管线完成 ---\\n\")\n","    return results"],"metadata":{"id":"gYObicJAqawE","executionInfo":{"status":"ok","timestamp":1760432158440,"user_tz":-180,"elapsed":31,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","root_dir = \"/content/drive/MyDrive/data\"\n","res = analyze_eeg_sound_data(root_dir, save_dir=\"/content/eeg_sound_results\")\n","print(json.dumps({\n","    \"NoiseCeiling\": res[\"noise_ceiling_pc1\"],\n","    \"Lag-PC1\": res[\"lag_alignment\"][\"pc1\"],\n","    \"Lag-Env\": res[\"lag_alignment\"][\"envelope\"],\n","    \"ROI-Overall\": res[\"channel_roi_summary\"][\"overall_summary\"],\n","    \"TRF-Overall\": res[\"trf_results_per_subject\"][\"overall_summary\"]\n","}, ensure_ascii=False, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ld-sKylJqXiA","executionInfo":{"status":"ok","timestamp":1760434635668,"user_tz":-180,"elapsed":2477230,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"b23aed04-fd89-47ac-9d9e-4b6435ea4e61"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 开始数据分析管线 ---\n","开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [01:26<00:00,  4.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1794 个数据段。\n","过滤结果：总 1794 段 -> 保留 1794 段 | 空T: 0, 空D: 0, 过短(<20帧): 0\n","EEG: 段数=1794, 含NaN段=0 (0.0%), 含Inf段=0 (0.0%)\n","Sound: 段数=1794, 含NaN段=1794 (100.0%), 含Inf段=0 (0.0%)\n","\n","=== 声音特征 NaN 概览 ===\n","- 段级：含NaN的段 = 1794/1794 (100.0%); 中位数NaN率 = 16.67%\n","- 列级（跨段平均）前10个最差列及其NaN率：\n","  列52: 平均NaN率=99.69%\n","  列51: 平均NaN率=99.22%\n","  列50: 平均NaN率=99.22%\n","  列48: 平均NaN率=99.22%\n","  列45: 平均NaN率=99.22%\n","  列46: 平均NaN率=99.22%\n","  列47: 平均NaN率=99.22%\n","  列49: 平均NaN率=99.22%\n","  列53: 平均NaN率=99.22%\n","  列0: 平均NaN率=0.00%\n"]},{"output_type":"stream","name":"stderr","text":["修复声音特征: 100%|██████████| 1794/1794 [00:03<00:00, 500.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["修复完成：平均保留列数 = 45.062430323299886  / 平均原始列数 = 54.0\n","\n","=== 基于 PC1 的分块噪声上限 ===\n","{\n","  \"r_eeg_blk_overall_PC1\": 0.6935338185221477,\n","  \"r_sound_blk_overall_PC1\": 0.27392708407007144,\n","  \"r_max_blk_overall_PC1\": 0.4358643098623171\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Lag PC1 / Envelope: 100%|██████████| 1794/1794 [01:50<00:00, 16.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 时延（PC1↔PC1）汇总 ===\n","{\n","  \"median_peak_r\": 0.1365618066091414,\n","  \"median_peak_lag_ms\": 55.0,\n","  \"median_peak_r_null\": 0.14892065585890285,\n","  \"frac_r_gt_null\": 0.4793756967670011\n","}\n","\n","=== 时延（PC1↔Envelope）汇总 ===\n","{\n","  \"median_peak_r\": 0.12626358925003917,\n","  \"median_peak_lag_ms\": 44.0,\n","  \"median_peak_r_null\": 0.15050690789462307,\n","  \"frac_r_gt_null\": 0.463768115942029\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Channelwise ROI: 100%|██████████| 1794/1794 [16:11<00:00,  1.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 通道级 ROI 汇总 ===\n","{\n","  \"median_peak_r\": 0.21005677445726784,\n","  \"median_peak_lag_ms\": 11.0,\n","  \"median_peak_r_null\": 0.13534070860063452,\n","  \"frac_r_gt_null\": 0.8876146788990825,\n","  \"top_channels\": [\n","    [\n","      10,\n","      147\n","    ],\n","    [\n","      1,\n","      126\n","    ],\n","    [\n","      28,\n","      77\n","    ],\n","    [\n","      23,\n","      75\n","    ],\n","    [\n","      4,\n","      74\n","    ],\n","    [\n","      8,\n","      74\n","    ],\n","    [\n","      5,\n","      73\n","    ],\n","    [\n","      11,\n","      70\n","    ],\n","    [\n","      17,\n","      67\n","    ],\n","    [\n","      14,\n","      65\n","    ]\n","  ]\n","}\n"]},{"output_type":"stream","name":"stderr","text":["TRF per subject: 100%|██████████| 15/15 [21:33<00:00, 86.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== TRF（总体）===\n","{\n","  \"median_of_subject_medians\": 0.012809939369599645,\n","  \"median_of_subject_nulls\": -0.003862342276028379,\n","  \"frac_subjects_better_than_null\": 0.8,\n","  \"median_TRF_peak_ms_(>=0)\": 121.0\n","}\n","结果已保存到: /content/eeg_sound_results\n","--- 数据分析管线完成 ---\n","\n","{\n","  \"NoiseCeiling\": {\n","    \"r_eeg_blk_overall_PC1\": 0.6935338185221477,\n","    \"r_sound_blk_overall_PC1\": 0.27392708407007144,\n","    \"r_max_blk_overall_PC1\": 0.4358643098623171\n","  },\n","  \"Lag-PC1\": {\n","    \"median_peak_r\": 0.1365618066091414,\n","    \"median_peak_lag_ms\": 55.0,\n","    \"median_peak_r_null\": 0.14892065585890285,\n","    \"frac_r_gt_null\": 0.4793756967670011\n","  },\n","  \"Lag-Env\": {\n","    \"median_peak_r\": 0.12626358925003917,\n","    \"median_peak_lag_ms\": 44.0,\n","    \"median_peak_r_null\": 0.15050690789462307,\n","    \"frac_r_gt_null\": 0.463768115942029\n","  },\n","  \"ROI-Overall\": {\n","    \"median_peak_r\": 0.21005677445726784,\n","    \"median_peak_lag_ms\": 11.0,\n","    \"median_peak_r_null\": 0.13534070860063452,\n","    \"frac_r_gt_null\": 0.8876146788990825,\n","    \"top_channels\": [\n","      [\n","        10,\n","        147\n","      ],\n","      [\n","        1,\n","        126\n","      ],\n","      [\n","        28,\n","        77\n","      ],\n","      [\n","        23,\n","        75\n","      ],\n","      [\n","        4,\n","        74\n","      ],\n","      [\n","        8,\n","        74\n","      ],\n","      [\n","        5,\n","        73\n","      ],\n","      [\n","        11,\n","        70\n","      ],\n","      [\n","        17,\n","        67\n","      ],\n","      [\n","        14,\n","        65\n","      ]\n","    ]\n","  },\n","  \"TRF-Overall\": {\n","    \"median_of_subject_medians\": 0.012809939369599645,\n","    \"median_of_subject_nulls\": -0.003862342276028379,\n","    \"frac_subjects_better_than_null\": 0.8,\n","    \"median_TRF_peak_ms_(>=0)\": 121.0\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# =======================\n","# 上游数据与对齐（Colab一键版）\n","# 目标：在 root/Subject/feature_causal/ 下生成新的 Sound_aligned.npy + Sound_voicing.npy\n","# 关键：全程“因果/左对齐”，避免零相位；确保与 EEG 的帧数 T 一致\n","# 依赖：librosa, soundfile, scipy（Colab自带scipy，librosa需要安装）\n","# =======================\n","# !pip -q install librosa soundfile\n","\n","import os, glob, json, math, shutil\n","import numpy as np\n","import soundfile as sf\n","import librosa\n","from scipy.signal import lfilter\n","from tqdm import tqdm\n","\n","# ---------- 基础参数（可按需修改） ----------\n","FRAME_MS = 11.0         # 与现有管线一致\n","SR_TARGET = 16000       # 若音频采样率不一致，将重采样至此\n","N_MELS = 40\n","N_FFT_MS = 25.0         # STFT窗长（毫秒），与RMS窗一致\n","PREEMPH = 0.97          # 因果预加重系数\n","ADD_DELTAS = False      # 如需加一阶delta，可改 True\n","VOICING_PCT = 60        # voicing门限的RMS分位点（段内百分位）\n","GLOBAL_OFFSET_MS = 0.0  # 可选：若已知音频需整体延后/提前，对音频作整体移位（+为延后）\n","\n","# ---------- 工具 ----------\n","def next_pow2(n):\n","    p = 1\n","    while p < n:\n","        p <<= 1\n","    return p\n","\n","def ensure_dir(p):\n","    os.makedirs(p, exist_ok=True)\n","\n","def causal_shift_signal(y, sr, shift_ms):\n","    \"\"\"对音频做整体因果移位：shift_ms>0 => 向后推迟（前面补零）\"\"\"\n","    if abs(shift_ms) < 1e-6:\n","        return y\n","    shift_samp = int(round(sr * shift_ms / 1000.0))\n","    if shift_samp > 0:\n","        return np.concatenate([np.zeros(shift_samp, dtype=y.dtype), y])\n","    else:\n","        return y[-shift_samp:]  # 负移位：裁掉前面\n","\n","def find_audio_for_segment(subject_root, base_name):\n","    \"\"\"\n","    在被试目录内尝试找到与 base_name 匹配的音频文件。\n","    优先顺序：与特征同目录 / audio/ / wav/ / 整个subject内递归查找。\n","    \"\"\"\n","    cand_names = [\n","        base_name.strip(\".\") + \".wav\",\n","        base_name.strip(\".\") + \".flac\",\n","        base_name.strip(\".\") + \".mp3\",\n","    ]\n","    # 常见位置\n","    for sub in [\"feature_normalized\", \".\", \"audio\", \"wav\", \"Audio\", \"WAV\"]:\n","        d = os.path.join(subject_root, sub)\n","        for cn in cand_names:\n","            p = os.path.join(d, cn)\n","            if os.path.exists(p):\n","                return p\n","    # 递归兜底\n","    for ext in (\"*.wav\",\"*.flac\",\"*.mp3\"):\n","        hits = glob.glob(os.path.join(subject_root, \"**\", ext), recursive=True)\n","        hits = [h for h in hits if os.path.basename(h).startswith(os.path.basename(base_name).strip(\".\"))]\n","        if hits:\n","            return hits[0]\n","    return None\n","\n","def causal_features_from_audio(wav_path, T_target, frame_ms=FRAME_MS, sr_target=SR_TARGET,\n","                               n_mels=N_MELS, n_fft_ms=N_FFT_MS, preemph=PREEMPH, add_deltas=ADD_DELTAS,\n","                               voicing_pct=VOICING_PCT, global_offset_ms=GLOBAL_OFFSET_MS):\n","    \"\"\"\n","    从音频构造因果特征矩阵（T×D）与voicing掩码（T,）：\n","    - 左对齐帧: hop=frame_ms, center=False\n","    - 预加重采用因果lfilter\n","    - log-mel + RMS（附在最后一列），无NaN；可选 delta\n","    \"\"\"\n","    y, sr = sf.read(wav_path, always_2d=False)\n","    if y.ndim > 1:\n","        y = np.mean(y, axis=1)  # to mono\n","    if sr != sr_target:\n","        y = librosa.resample(y.astype(np.float32), orig_sr=sr, target_sr=sr_target, res_type=\"kaiser_fast\")\n","        sr = sr_target\n","\n","    # 全局时间移位（若需要整体对齐补偿）\n","    y = causal_shift_signal(y, sr, global_offset_ms).astype(np.float32)\n","\n","    # 因果预加重（y[n] - a*y[n-1]）\n","    y = lfilter([1.0, -preemph], [1.0], y)\n","\n","    hop = int(round(sr * frame_ms / 1000.0))\n","    win = int(round(sr * n_fft_ms / 1000.0))\n","    n_fft = next_pow2(win)\n","\n","    # STFT 特征（左对齐、因果窗；不使用center=True）\n","    S = librosa.feature.melspectrogram(\n","        y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop, win_length=win,\n","        center=False, power=2.0\n","    )  # (n_mels, T0)\n","    S_db = librosa.power_to_db(S + 1e-12, ref=np.max)  # 对数能量（不会有NaN）\n","    # RMS 包络（同样 left-aligned、center=False）\n","    rms = librosa.feature.rms(y=y, frame_length=win, hop_length=hop, center=False)[0]  # (T0,)\n","\n","    # 可选：Δ\n","    feats = [S_db.T]  # (T0, n_mels)\n","    if add_deltas:\n","        d1 = librosa.feature.delta(S_db, order=1).T\n","        feats.append(d1)\n","    feats.append(rms[:, None])  # 附加 RMS 一列\n","    X = np.concatenate(feats, axis=1).astype(np.float32)  # (T0, D)\n","\n","    # 因果/左对齐到 EEG 帧数：严格截断或零填充以匹配 T_target\n","    T0 = X.shape[0]\n","    if T0 < T_target:\n","        pad = np.zeros((T_target - T0, X.shape[1]), dtype=np.float32)\n","        X = np.vstack([X, pad])\n","        rms2 = np.concatenate([rms, np.zeros(T_target - T0, dtype=np.float32)])\n","    else:\n","        X = X[:T_target]\n","        rms2 = rms[:T_target]\n","\n","    # 段内分位点阈值做 voicing 掩码（因果阈值本身不引入相位）\n","    finite_rms = rms2[np.isfinite(rms2)]\n","    thr = np.percentile(finite_rms, voicing_pct) if finite_rms.size else 0.0\n","    voicing = (rms2 > thr)\n","\n","    # 时间向 z-score（逐列），避免尺度漂移；RMS 列也 z 但不影响voicing\n","    mu = np.nanmean(X, axis=0, keepdims=True); sd = np.nanstd(X, axis=0, keepdims=True); sd[sd==0] = 1.0\n","    Xz = (X - mu) / sd\n","    Xz[~np.isfinite(Xz)] = 0.0\n","\n","    return Xz.astype(np.float32), voicing.astype(np.bool_)\n","\n","def causal_features_from_existing_matrix(S_old, T_target, frame_ms=FRAME_MS, n_mels=0,\n","                                         voicing_cols_guess=None, voicing_pct=VOICING_PCT):\n","    \"\"\"\n","    兜底：若没有原始音频，用现有 Sound_aligned.npy 自救\n","    - 丢弃高NaN列、插值、z-score（与清洗一致）\n","    - 生成L2包络+RMS代理（从矩阵行范数），拼在最后\n","    - voicing：优先用高NaN列构造掩码，否则用能量分位点\n","    \"\"\"\n","    S = np.array(S_old, dtype=np.float32, copy=True)\n","    T, D = S.shape\n","    # 丢弃 >60% NaN 的列\n","    nan_rate = np.mean(~np.isfinite(S), axis=0)\n","    keep = nan_rate <= 0.6\n","    if keep.sum() == 0:\n","        X = np.zeros((T_target, 1), dtype=np.float32)\n","    else:\n","        S2 = S[:, keep]\n","        # 时间向插值 + 端点外推\n","        for d in range(S2.shape[1]):\n","            col = S2[:, d]\n","            m = np.isfinite(col)\n","            if m.sum() == 0:\n","                S2[:, d] = 0.0\n","            else:\n","                idx = np.arange(T)\n","                S2[~m, d] = np.interp(idx[~m], idx[m], col[m])\n","        # z\n","        mu = S2.mean(0, keepdims=True); sd = S2.std(0, keepdims=True); sd[sd==0]=1.0\n","        S2 = (S2 - mu)/sd\n","        # L2 包络\n","        env = np.sqrt((S2**2).sum(axis=1, keepdims=True))\n","        X = np.hstack([S2, env]).astype(np.float32)\n","\n","    # 匹配 T\n","    if T < T_target:\n","        pad = np.zeros((T_target-T, X.shape[1]), dtype=np.float32)\n","        X = np.vstack([X, pad])\n","        env1 = np.concatenate([X[:T, -1], np.zeros(T_target-T, dtype=np.float32)])\n","    else:\n","        X = X[:T_target]\n","        env1 = X[:T_target, -1]\n","\n","    # voicing\n","    if voicing_cols_guess is not None and len(voicing_cols_guess) > 0:\n","        m = np.any(np.isfinite(S[:, [c for c in voicing_cols_guess if c < D]]), axis=1)\n","        if T < T_target:\n","            m = np.concatenate([m, np.zeros(T_target-T, dtype=bool)])\n","        else:\n","            m = m[:T_target]\n","        voicing = m\n","    else:\n","        thr = np.percentile(env1[np.isfinite(env1)], voicing_pct) if np.any(np.isfinite(env1)) else 0.0\n","        voicing = env1 > thr\n","\n","    return X.astype(np.float32), voicing.astype(np.bool_)\n","\n","def build_upstream_for_all(root_dir,\n","                           old_root_suffix=\"feature_normalized\",\n","                           new_root_suffix=\"feature_causal\",\n","                           frame_ms=FRAME_MS, sr_target=SR_TARGET,\n","                           n_mels=N_MELS, n_fft_ms=N_FFT_MS,\n","                           preemph=PREEMPH, add_deltas=ADD_DELTAS,\n","                           voicing_pct=VOICING_PCT, global_offset_ms=GLOBAL_OFFSET_MS):\n","    \"\"\"\n","    对所有被试、所有段：\n","    - 读取 EEG_aligned.npy（获得 T）\n","    - 尝试匹配音频并生成因果特征；若找不到音频，使用旧矩阵自救\n","    - 保存到 Subject/new_root_suffix/ 同名文件：\n","        * Sound_aligned.npy  （新的因果特征）\n","        * Sound_voicing.npy  （布尔掩码）\n","        * EEG_aligned.npy    （从旧目录复制，确保载入兼容）\n","        * meta.json          （记录参数）\n","    \"\"\"\n","    subjects = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]\n","    total_done = 0; total_audio = 0; total_fallback = 0\n","\n","    for subj in tqdm(subjects, desc=\"Subjects\"):\n","        subj_root = os.path.join(root_dir, subj)\n","        old_dir = os.path.join(subj_root, old_root_suffix)\n","        new_dir = os.path.join(subj_root, new_root_suffix)\n","        if not os.path.isdir(old_dir):\n","            continue\n","        ensure_dir(new_dir)\n","\n","        eeg_files = glob.glob(os.path.join(old_dir, \"*EEG_aligned.npy\"))\n","        for eeg_path in eeg_files:\n","            base = os.path.basename(eeg_path).replace(\"EEG_aligned.npy\", \"\")\n","            sound_old_path = os.path.join(old_dir, base + \"Sound_aligned.npy\")\n","            # 载入 EEG 以获知 T\n","            try:\n","                E = np.load(eeg_path)\n","                T_target = E.shape[0]\n","            except Exception as e:\n","                print(\"EEG载入失败，跳过：\", eeg_path, e); continue\n","\n","            # 搜索音频\n","            wav_path = find_audio_for_segment(subj_root, base)\n","            # 生成新特征\n","            try:\n","                if wav_path and os.path.exists(wav_path):\n","                    X, vm = causal_features_from_audio(\n","                        wav_path, T_target, frame_ms, sr_target,\n","                        n_mels, n_fft_ms, preemph, add_deltas,\n","                        voicing_pct, global_offset_ms\n","                    )\n","                    total_audio += 1\n","                else:\n","                    # 若无音频，则用旧矩阵兜底\n","                    if os.path.exists(sound_old_path):\n","                        S_old = np.load(sound_old_path)\n","                    else:\n","                        # 若连旧矩阵也不存在，就造一个全零占位\n","                        S_old = np.zeros((T_target, N_MELS), dtype=np.float32)\n","                    # 猜 voicing 列（极高NaN率）\n","                    if os.path.exists(sound_old_path):\n","                        nan_rate = np.mean(~np.isfinite(S_old), axis=0)\n","                        voicing_cols_guess = np.where(nan_rate > 0.95)[0]\n","                    else:\n","                        voicing_cols_guess = None\n","                    X, vm = causal_features_from_existing_matrix(S_old, T_target, frame_ms, voicing_cols_guess=voicing_cols_guess)\n","                    total_fallback += 1\n","            except Exception as e:\n","                print(\"特征构造失败，跳过：\", base, e); continue\n","\n","            # 保存：Sound, voicing, EEG（复制）\n","            np.save(os.path.join(new_dir, base + \"Sound_aligned.npy\"), X.astype(np.float32))\n","            np.save(os.path.join(new_dir, base + \"Sound_voicing.npy\"), vm.astype(np.bool_))\n","            # 复制 EEG 对齐文件，保持加载兼容性\n","            eeg_new_path = os.path.join(new_dir, base + \"EEG_aligned.npy\")\n","            if not os.path.exists(eeg_new_path):\n","                try:\n","                    shutil.copy2(eeg_path, eeg_new_path)\n","                except Exception as e:\n","                    print(\"复制EEG失败：\", eeg_path, \"->\", eeg_new_path, e)\n","\n","            # 元信息\n","            meta = dict(\n","                sr_target=sr_target, frame_ms=frame_ms, n_fft_ms=n_fft_ms, n_mels=n_mels,\n","                preemph=preemph, add_deltas=add_deltas, voicing_pct=voicing_pct,\n","                global_offset_ms=global_offset_ms, used_audio=bool(wav_path and os.path.exists(wav_path)),\n","                wav_path=wav_path if wav_path else None\n","            )\n","            with open(os.path.join(new_dir, base + \"meta.json\"), \"w\") as f:\n","                json.dump(meta, f, ensure_ascii=False, indent=2)\n","\n","            total_done += 1\n","\n","    print(f\"\\n完成上游构建：总段数={total_done} | 使用音频构建={total_audio} | 兜底自救={total_fallback}\")\n","    print(\"已输出至各被试的\", new_root_suffix, \"目录。\")\n","\n","# ---------- 与现有分析管线对接 ----------\n","def analyze_with_causal_features(root_dir):\n","    \"\"\"\n","    用新的 feature_causal 目录跑你已有的分析流程（无需改动核心代码）：\n","    - 直接用 load_segments_with_subject_ids(root_suffix='feature_causal') 即可\n","    \"\"\"\n","    # 复用你现有的函数（确保之前的分析函数已在环境里）\n","    eeg_segments, sound_segments, subject_ids = load_segments_with_subject_ids(root_dir, root_suffix=\"feature_causal\")\n","    # 后续就按你现有管线跑：\n","    # 例如：eeg_segments, sound_segments, subject_ids = filter_and_summarize(...)\n","    #       percol_nan_mean = summarize_sound_nan(sound_segments)\n","    #       sound_repaired, drop_stats = batch_repair_sound(sound_segments, drop_thr=0.6)\n","    #       ... 或直接调用你已装配的 analyze_eeg_sound_data 替身版本\n","    return eeg_segments, sound_segments, subject_ids\n","\n","\n"],"metadata":{"id":"tp0cRXqxs75M","executionInfo":{"status":"ok","timestamp":1760434636119,"user_tz":-180,"elapsed":449,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# ========== 使用示例 ==========\n","# 1) 指定数据根目录\n","root_dir = \"/content/drive/MyDrive/data\"\n","\n","# 2) 生成新的“因果对齐”的声学特征\n","build_upstream_for_all(root_dir,\n","                       old_root_suffix=\"feature_normalized\",\n","                       new_root_suffix=\"feature_causal\",\n","                       frame_ms=FRAME_MS, sr_target=SR_TARGET,\n","                       n_mels=N_MELS, n_fft_ms=N_FFT_MS,\n","                       preemph=PREEMPH, add_deltas=ADD_DELTAS,\n","                       voicing_pct=VOICING_PCT, global_offset_ms=GLOBAL_OFFSET_MS)\n","\n","# 3) 用新的特征目录跑现有分析（把 root_suffix 改为 'feature_causal'）\n","eeg_segments, sound_segments, subject_ids = analyze_with_causal_features(root_dir)\n","\n","# 或者如果你使用我给的整合管线 analyze_eeg_sound_data，可写一个轻量封装版本：\n","results = analyze_eeg_sound_data(root_dir, save_dir=\"/content/eeg_sound_results_causal\")"],"metadata":{"id":"0JjjoxTmtF2Q","executionInfo":{"status":"ok","timestamp":1760438873003,"user_tz":-180,"elapsed":4236854,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8fb00ca-a5a0-49a2-833b-aafff7549bd8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Subjects: 100%|██████████| 20/20 [28:47<00:00, 86.38s/it] \n"]},{"output_type":"stream","name":"stdout","text":["\n","完成上游构建：总段数=1794 | 使用音频构建=0 | 兜底自救=1794\n","已输出至各被试的 feature_causal 目录。\n","开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [01:38<00:00,  4.93s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1794 个数据段。\n","\n","--- 开始数据分析管线 ---\n","开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [00:27<00:00,  1.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1794 个数据段。\n","过滤结果：总 1794 段 -> 保留 1794 段 | 空T: 0, 空D: 0, 过短(<20帧): 0\n","EEG: 段数=1794, 含NaN段=0 (0.0%), 含Inf段=0 (0.0%)\n","Sound: 段数=1794, 含NaN段=1794 (100.0%), 含Inf段=0 (0.0%)\n","\n","=== 声音特征 NaN 概览 ===\n","- 段级：含NaN的段 = 1794/1794 (100.0%); 中位数NaN率 = 16.67%\n","- 列级（跨段平均）前10个最差列及其NaN率：\n","  列52: 平均NaN率=99.69%\n","  列51: 平均NaN率=99.22%\n","  列50: 平均NaN率=99.22%\n","  列48: 平均NaN率=99.22%\n","  列45: 平均NaN率=99.22%\n","  列46: 平均NaN率=99.22%\n","  列47: 平均NaN率=99.22%\n","  列49: 平均NaN率=99.22%\n","  列53: 平均NaN率=99.22%\n","  列0: 平均NaN率=0.00%\n"]},{"output_type":"stream","name":"stderr","text":["修复声音特征: 100%|██████████| 1794/1794 [00:03<00:00, 486.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["修复完成：平均保留列数 = 45.062430323299886  / 平均原始列数 = 54.0\n","\n","=== 基于 PC1 的分块噪声上限 ===\n","{\n","  \"r_eeg_blk_overall_PC1\": 0.6935338185221477,\n","  \"r_sound_blk_overall_PC1\": 0.27392708407007144,\n","  \"r_max_blk_overall_PC1\": 0.4358643098623171\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Lag PC1 / Envelope: 100%|██████████| 1794/1794 [01:45<00:00, 17.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 时延（PC1↔PC1）汇总 ===\n","{\n","  \"median_peak_r\": 0.1365618066091414,\n","  \"median_peak_lag_ms\": 55.0,\n","  \"median_peak_r_null\": 0.14892065585890285,\n","  \"frac_r_gt_null\": 0.4793756967670011\n","}\n","\n","=== 时延（PC1↔Envelope）汇总 ===\n","{\n","  \"median_peak_r\": 0.12626358925003917,\n","  \"median_peak_lag_ms\": 44.0,\n","  \"median_peak_r_null\": 0.15050690789462307,\n","  \"frac_r_gt_null\": 0.463768115942029\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Channelwise ROI: 100%|██████████| 1794/1794 [15:58<00:00,  1.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 通道级 ROI 汇总 ===\n","{\n","  \"median_peak_r\": 0.21005677445726784,\n","  \"median_peak_lag_ms\": 11.0,\n","  \"median_peak_r_null\": 0.13534070860063452,\n","  \"frac_r_gt_null\": 0.8876146788990825,\n","  \"top_channels\": [\n","    [\n","      10,\n","      147\n","    ],\n","    [\n","      1,\n","      126\n","    ],\n","    [\n","      28,\n","      77\n","    ],\n","    [\n","      23,\n","      75\n","    ],\n","    [\n","      4,\n","      74\n","    ],\n","    [\n","      8,\n","      74\n","    ],\n","    [\n","      5,\n","      73\n","    ],\n","    [\n","      11,\n","      70\n","    ],\n","    [\n","      17,\n","      67\n","    ],\n","    [\n","      14,\n","      65\n","    ]\n","  ]\n","}\n"]},{"output_type":"stream","name":"stderr","text":["TRF per subject: 100%|██████████| 15/15 [21:47<00:00, 87.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== TRF（总体）===\n","{\n","  \"median_of_subject_medians\": 0.012809939369599645,\n","  \"median_of_subject_nulls\": -0.003862342276028379,\n","  \"frac_subjects_better_than_null\": 0.8,\n","  \"median_TRF_peak_ms_(>=0)\": 121.0\n","}\n","结果已保存到: /content/eeg_sound_results_causal\n","--- 数据分析管线完成 ---\n","\n"]}]},{"cell_type":"code","source":["!pip -q install resampy==0.4.3\n"],"metadata":{"id":"EKhR8QuO5yfW","executionInfo":{"status":"ok","timestamp":1760438876733,"user_tz":-180,"elapsed":3726,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaf32557-013b-49ac-f8a7-47078b6c6534"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m2.7/3.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# ============================================\n","# 根据 CSV(wav_filename_base) + 原音频(Stimuli) 生成新声学特征\n","# 左对齐/因果预处理 + 与 EEG 段对齐（通过与旧特征包络互相关来定位）\n","# 输出到: <subject>/feature_from_wav_causal/\n","# 依赖: librosa, soundfile\n","# ============================================\n","!pip -q install librosa soundfile\n","\n","import os, glob, json, math, shutil\n","import numpy as np\n","import pandas as pd\n","import librosa, soundfile as sf\n","from scipy.signal import lfilter\n","from tqdm import tqdm\n","import math\n","import numpy as np\n","import librosa, soundfile as sf\n","from scipy.signal import lfilter, resample_poly\n","\n","# ---------- 基本参数 ----------\n","root_dir = \"/content/drive/MyDrive/data\"\n","stimuli_dir = \"/content/drive/MyDrive/data/Stimuli/Stimuli\"\n","\n","FRAME_MS   = 11.0   # 每帧时长，与现有管线一致\n","SR_TARGET  = 16000  # 统一采样率\n","N_MELS     = 40\n","WIN_MS     = 25.0   # STFT窗长\n","PREEMPH    = 0.97   # 因果预加重系数\n","ADD_DELTAS = False  # 是否添加delta\n","VOICING_PCT = 60    # 段内RMS分位点做有声阈值\n","NEW_SUFFIX = \"feature_from_wav_causal\"  # 新输出目录名\n","OLD_SUFFIX = \"feature_normalized\"       # 旧特征目录，用于对齐参照\n","\n","# ---------- 工具 ----------\n","def ensure_dir(p): os.makedirs(p, exist_ok=True)\n","\n","def next_pow2(n):\n","    p = 1\n","    while p < n: p <<= 1\n","    return p\n","\n","def load_subject_csv(subject_dir):\n","    \"\"\"寻找并读取 artifact/*.csv；返回DataFrame（如果没找到返回None）。\"\"\"\n","    cands = glob.glob(os.path.join(subject_dir, \"artifact\", \"*.csv\"))\n","    if not cands:\n","        return None\n","    # 如果有多个，取名字最“像”的（也可以直接取第一个）\n","    cands.sort()\n","    return pd.read_csv(cands[0])\n","\n","def build_stimuli_index(stim_dir):\n","    \"\"\"建立 {basename(不含扩展): 完整路径} 的索引。\"\"\"\n","    idx = {}\n","    for p in glob.glob(os.path.join(stim_dir, \"*.wav\")):\n","        base = os.path.splitext(os.path.basename(p))[0]\n","        idx[base] = p\n","    return idx\n","\n","\n","def _resample_with_scipy(y, orig_sr, target_sr):\n","    if orig_sr == target_sr:\n","        return y.astype(np.float32, copy=False)\n","    g = math.gcd(int(orig_sr), int(target_sr))\n","    up, down = int(target_sr//g), int(orig_sr//g)\n","    return resample_poly(y.astype(np.float32, copy=False), up, down).astype(np.float32)\n","\n","def causal_audio_features(wav_path, sr_target=16000, frame_ms=11.0, win_ms=25.0,\n","                          n_mels=40, preemph=0.97, add_deltas=False):\n","    # 读 & 重采样（不用 resampy）\n","    y, sr = sf.read(wav_path, always_2d=False)\n","    if y.ndim > 1:\n","        y = np.mean(y, axis=1)\n","    y = _resample_with_scipy(y, sr, sr_target)\n","    sr = sr_target\n","\n","    # 因果预加重\n","    y = lfilter([1.0, -preemph], [1.0], y).astype(np.float32)\n","\n","    hop = int(round(sr * frame_ms / 1000.0))\n","    win = int(round(sr * win_ms  / 1000.0))\n","\n","    # 关键：n_fft 与 win 完全一致，center=False\n","    n_fft = win\n","\n","    S = librosa.feature.melspectrogram(\n","        y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop, win_length=win,\n","        center=False, power=2.0\n","    )  # (n_mels, Tm)\n","    S_db = librosa.power_to_db(S + 1e-12, ref=np.max)\n","\n","    rms = librosa.feature.rms(y=y, frame_length=win, hop_length=hop, center=False)[0]  # (Tr,)\n","\n","    # 安全对齐：取共同最小帧数\n","    T0 = min(S_db.shape[1], rms.shape[0])\n","    if T0 <= 0:\n","        # 兜底：返回空特征\n","        return np.zeros((0, n_mels + (n_mels if add_deltas else 0) + 1), dtype=np.float32), \\\n","               np.zeros((0,), dtype=np.float32), \\\n","               np.zeros((0,), dtype=np.float32)\n","    S_db = S_db[:, :T0]\n","    rms  = rms[:T0]\n","\n","    feats = [S_db.T]  # (T0, n_mels)\n","    if add_deltas:\n","        d1 = librosa.feature.delta(S_db, order=1).T  # 与 S_db 同 T0\n","        feats.append(d1)\n","    feats.append(rms[:, None])  # (T0, 1)\n","    X = np.concatenate(feats, axis=1).astype(np.float32)\n","\n","    # 列 z-score\n","    mu = X.mean(axis=0, keepdims=True)\n","    sd = X.std(axis=0, keepdims=True); sd[sd==0] = 1.0\n","    Xz = (X - mu) / sd\n","\n","    # mel-L2 包络（标准化，用于对齐/质检）\n","    mel = Xz[:, :n_mels]\n","    env = np.sqrt((mel**2).sum(axis=1)).astype(np.float32)\n","    env = (env - env.mean()) / (env.std() if env.std()>0 else 1.0)\n","\n","    return Xz.astype(np.float32), env.astype(np.float32), rms.astype(np.float32)\n","\n","print(\"✅ Patched causal_audio_features: n_fft == win, frames aligned.\")\n","\n","# 2) 保险：若其他代码调用了 librosa.resample，则把它指向 SciPy 版本\n","def _librosa_resample_wrapper(y, orig_sr, target_sr, *args, **kwargs):\n","    return _resample_with_scipy(np.asarray(y), orig_sr, target_sr)\n","\n","try:\n","    librosa.resample = _librosa_resample_wrapper\n","except Exception:\n","    pass\n","def envelope_from_old_matrix(S_old):\n","    \"\"\"从旧的 Sound_aligned.npy 构造一个稳健包络（丢高NaN列、时间插值）。\"\"\"\n","    S = np.array(S_old, dtype=np.float32, copy=True)\n","    T, D = S.shape\n","    nan_rate = np.mean(~np.isfinite(S), axis=0)\n","    keep = nan_rate <= 0.6\n","    if keep.sum() == 0:\n","        return np.zeros(T, dtype=np.float32)\n","    S2 = S[:, keep]\n","    # 时间向插值\n","    idx = np.arange(T)\n","    for d in range(S2.shape[1]):\n","        col = S2[:, d]\n","        m = np.isfinite(col)\n","        if m.sum() == 0: S2[:, d] = 0.0\n","        else: S2[~m, d] = np.interp(idx[~m], idx[m], col[m])\n","    # 列z\n","    mu = S2.mean(axis=0, keepdims=True)\n","    sd = S2.std(axis=0, keepdims=True); sd[sd==0]=1.0\n","    Z = (S2 - mu)/sd\n","    env = np.sqrt((Z**2).sum(axis=1))\n","    return (env - env.mean())/(env.std() if env.std()>0 else 1.0)\n","\n","def crosscorr_align_offset(ref_env, full_env, max_search=None):\n","    \"\"\"\n","    在 full_env 里寻找与 ref_env（长度T_ref）最匹配的起点。\n","    返回起点索引 start（使得 full_env[start:start+T_ref] 与 ref_env 的相关最大）。\n","    如果 max_search 设定，将搜索窗口限制在 [0, max_search]。\n","    \"\"\"\n","    T_ref = len(ref_env); T_full = len(full_env)\n","    if T_full < T_ref:\n","        return 0\n","    # 为避免O(T^2)极慢，做简单而稳健的“窗口滑动 z-score 相关”\n","    # 这里为了简洁，直接粗略子采样搜索步长 = 1（帧），一般音频帧数也不至于太大\n","    # 可选：如果非常长，可设 stride>1，再在邻域细化（这里先用 stride=1）\n","    if max_search is None or max_search > T_full - T_ref:\n","        max_search = T_full - T_ref\n","    best_r, best_s = -np.inf, 0\n","    ref = (ref_env - np.mean(ref_env)) / (np.std(ref_env) if np.std(ref_env)>0 else 1.0)\n","    for s in range(0, max_search+1):\n","        seg = full_env[s:s+T_ref]\n","        if seg.std() == 0: continue\n","        r = np.corrcoef(ref, (seg - seg.mean())/seg.std())[0,1]\n","        if np.isfinite(r) and r > best_r:\n","            best_r, best_s = r, s\n","    return best_s\n","\n","def segment_from_full(X_full, start, T_target):\n","    \"\"\"从整段特征 X_full 中截取 [start, start+T_target)，不足补零。\"\"\"\n","    T_full, D = X_full.shape\n","    if start < 0: start = 0\n","    end = start + T_target\n","    if start >= T_full:\n","        return np.zeros((T_target, D), dtype=X_full.dtype)\n","    if end <= T_full:\n","        return X_full[start:end].copy()\n","    # 右侧不足补零\n","    pad = np.zeros((end - T_full, D), dtype=X_full.dtype)\n","    return np.vstack([X_full[start:T_full], pad])\n","\n","def voicing_from_rms(rms_seg, pct=VOICING_PCT):\n","    \"\"\"用段内 RMS 的分位点阈值得到有声掩码。\"\"\"\n","    x = rms_seg[np.isfinite(rms_seg)]\n","    thr = np.percentile(x, pct) if x.size else 0.0\n","    return (rms_seg > thr)\n","\n","# ---------- 主流程 ----------\n","def build_features_from_table_and_audio(root_dir, stimuli_dir,\n","                                        old_suffix=OLD_SUFFIX, new_suffix=NEW_SUFFIX):\n","    stim_index = build_stimuli_index(stimuli_dir)\n","    subjects = [s for s in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, s))]\n","    cache = {}  # 缓存每个wav的整段特征，避免重复计算：{wav_base: (X_full, env_full, rms_full)}\n","    total = 0\n","\n","    for subj in tqdm(subjects, desc=\"Subjects\"):\n","        subj_dir = os.path.join(root_dir, subj)\n","        old_dir  = os.path.join(subj_dir, old_suffix)\n","        if not os.path.isdir(old_dir):\n","            continue\n","        new_dir  = os.path.join(subj_dir, new_suffix)\n","        ensure_dir(new_dir)\n","\n","        # 读CSV，收集可能的 wav basenames\n","        df = load_subject_csv(subj_dir)\n","        wav_bases = []\n","        if df is not None and (\"WAV_Filename_Base\" in df.columns):\n","            wav_bases = sorted(set(os.path.splitext(os.path.basename(str(x)))[0]\n","                       for x in df[\"WAV_Filename_Base\"].dropna().tolist()))\n","\n","        else:\n","            print(f\"[警告] {subj} 未找到 CSV 或缺列 'wav_filename_base'，将尝试使用所有 Stimuli 下的 wav（不推荐）。\")\n","            wav_bases = list(stim_index.keys())\n","\n","        # 将可用的 wav 预加载/缓存\n","        for wb in wav_bases:\n","            if wb in cache:\n","                continue\n","            wav_path = stim_index.get(wb)\n","            if not wav_path or not os.path.exists(wav_path):\n","                print(f\"[警告] Stimuli 中找不到 {wb}.wav，跳过缓存预建。\")\n","                continue\n","            cache[wb] = causal_audio_features(wav_path)\n","\n","        # 遍历该被试的所有段\n","        eeg_files = glob.glob(os.path.join(old_dir, \"*EEG_aligned.npy\"))\n","        eeg_files.sort()\n","        for eeg_path in eeg_files:\n","            base = os.path.basename(eeg_path).replace(\"EEG_aligned.npy\",\"\")\n","            E = np.load(eeg_path)  # (T, C)\n","            T_target = E.shape[0]\n","\n","            # 旧声音（用于对齐参照）\n","            old_sound_path = os.path.join(old_dir, base + \"Sound_aligned.npy\")\n","            if not os.path.exists(old_sound_path):\n","                # 没有旧矩阵就无法通过互相关定位，只能从第一帧起截取\n","                S_old = None\n","                ref_env = None\n","            else:\n","                S_old = np.load(old_sound_path)\n","                ref_env = envelope_from_old_matrix(S_old)\n","\n","            # 选择音频：优先CSV里的唯一项；若多项，则挑与旧包络相关最高的那一个\n","            pick_wb, pick_start = None, 0\n","            best_r = -np.inf\n","            for wb in wav_bases:\n","                if wb not in cache:\n","                    wav_path = stim_index.get(wb)\n","                    if wav_path and os.path.exists(wav_path):\n","                        cache[wb] = causal_audio_features(wav_path)\n","                    else:\n","                        continue\n","                X_full, env_full, rms_full = cache[wb]\n","                # 定位起点\n","                if ref_env is not None and len(ref_env) > 10:\n","                    # 搜索上限：整段音频范围内都可以；可按需设定上限以加速\n","                    start = crosscorr_align_offset(ref_env, env_full, max_search=None)\n","                    # 计算对应窗口的相关，作为选择标准\n","                    seg = env_full[start:start+len(ref_env)]\n","                    if len(seg) == len(ref_env) and seg.std()>0 and np.std(ref_env)>0:\n","                        r = np.corrcoef((seg - seg.mean())/seg.std(),\n","                                        (ref_env - ref_env.mean())/ref_env.std())[0,1]\n","                    else:\n","                        r = -np.inf\n","                else:\n","                    # 没有参照包络，就从0开始\n","                    start, r = 0, 0.0\n","                if np.isfinite(r) and r > best_r:\n","                    best_r, pick_wb, pick_start = r, wb, start\n","\n","            if pick_wb is None:\n","                # 仍然找不到可用音频；用零矩阵占位\n","                print(f\"[警告] {subj}/{base}: 未找到匹配音频，输出零特征。\")\n","                X_seg = np.zeros((T_target, N_MELS + (N_MELS if ADD_DELTAS else 0) + 1), dtype=np.float32)\n","                rms_seg = np.zeros(T_target, dtype=np.float32)\n","            else:\n","                X_full, env_full, rms_full = cache[pick_wb]\n","                X_seg = segment_from_full(X_full, pick_start, T_target)\n","                rms_seg = segment_from_full(rms_full.reshape(-1,1), pick_start, T_target).ravel()\n","\n","            # 有声掩码\n","            vm = voicing_from_rms(rms_seg, pct=VOICING_PCT)\n","\n","            # 保存\n","            np.save(os.path.join(new_dir, base + \"Sound_aligned.npy\"), X_seg.astype(np.float32))\n","            np.save(os.path.join(new_dir, base + \"Sound_voicing.npy\"), vm.astype(np.bool_))\n","\n","            # 复制 EEG 对齐文件，保持加载兼容性\n","            eeg_new_path = os.path.join(new_dir, base + \"EEG_aligned.npy\")\n","            if not os.path.exists(eeg_new_path):\n","                shutil.copy2(eeg_path, eeg_new_path)\n","\n","            # 写 meta\n","            meta = dict(\n","                picked_wav_base=pick_wb,\n","                pick_start_frame=int(pick_start),\n","                frame_ms=FRAME_MS, sr_target=SR_TARGET,\n","                n_mels=N_MELS, win_ms=WIN_MS, preemph=PREEMPH,\n","                add_deltas=ADD_DELTAS, voicing_pct=VOICING_PCT,\n","                align_with=\"crosscorr(old_env, full_env)\", align_r=float(best_r) if np.isfinite(best_r) else None\n","            )\n","            with open(os.path.join(new_dir, base + \"meta.json\"), \"w\") as f:\n","                json.dump(meta, f, ensure_ascii=False, indent=2)\n","\n","            total += 1\n","\n","    print(f\"\\n完成！共输出 {total} 段到各被试的 '{NEW_SUFFIX}' 目录。\")\n","\n","# 运行构建\n","build_features_from_table_and_audio(root_dir, stimuli_dir)\n","\n","# （可选）随后把你的分析管线的 root_suffix 改为 'feature_from_wav_causal' 再跑一遍：\n"],"metadata":{"id":"caN2Q5MX0_K4","executionInfo":{"status":"ok","timestamp":1760441797476,"user_tz":-180,"elapsed":2920741,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"071c44e1-ba9c-4b00-961d-0a34d3016272"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Patched causal_audio_features: n_fft == win, frames aligned.\n"]},{"output_type":"stream","name":"stderr","text":["Subjects: 100%|██████████| 20/20 [48:32<00:00, 145.63s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","完成！共输出 1794 段到各被试的 'feature_from_wav_causal' 目录。\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# === Patch: 让 analyze_eeg_sound_data 支持 root_suffix 并实际使用它 ===\n","def analyze_eeg_sound_data(root_dir, frame_ms=11.0, max_lag_ms=300, null_shift_ratio=0.33,\n","                           min_frames=20, drop_thr=0.6, save_dir=None, root_suffix='feature_from_wav_causal'):\n","    \"\"\"\n","    分析 EEG 和 Sound 数据，计算噪声上限、时延对齐、通道级 ROI 和 TRF。\n","    新增参数：\n","        root_suffix (str): 指定从哪个子目录加载段（如 'feature_from_wav_causal' 或 'feature_causal' 或 'feature_normalized'）\n","    \"\"\"\n","    import os, json, numpy as np\n","    print(\"\\n--- 开始数据分析管线 ---\")\n","    print(f\"[INFO] 使用 root_suffix='{root_suffix}' 加载数据段\")\n","\n","    # 1) 加载（关键：使用 root_suffix）\n","    eegs, snds, sids = load_segments_with_subject_ids(root_dir, root_suffix=root_suffix)\n","\n","    # 2) 过滤\n","    eegs, snds, sids = filter_and_summarize(eegs, snds, sids, min_frames=min_frames)\n","\n","    # 报告 NaN/Inf（打印）\n","    nan_inf_report(eegs, snds)\n","\n","    # 3) 声音特征 NaN 概览 & 修复\n","    percol_nan_mean = summarize_sound_nan(snds)\n","    if percol_nan_mean is None:\n","        Dmax = max(S.shape[1] for S in snds) if snds else 0\n","        percol_nan_mean = np.zeros(Dmax)\n","    snds_rep, drop_stats = batch_repair_sound(snds, drop_thr=drop_thr)\n","\n","    # 4) 基于 PC1 的分块噪声上限\n","    r_eeg_blk, r_snd_blk, r_max_blk = noise_ceiling_from_pc1(eegs, snds_rep)\n","    noise_ceiling_pc1 = {\n","        \"r_eeg_blk_overall_PC1\": r_eeg_blk,\n","        \"r_sound_blk_overall_PC1\": r_snd_blk,\n","        \"r_max_blk_overall_PC1\": r_max_blk\n","    }\n","\n","    # 5) 时延：PC1↔PC1 与 PC1↔Envelope\n","    rows_pc1, rows_env = compute_lag_stats(eegs, snds_rep, frame_ms=frame_ms, max_lag_ms=max_lag_ms)\n","    def _summarize_lag_rows(rows):\n","        def med(key):\n","            vals = [r.get(key, np.nan) for r in rows if np.isfinite(r.get(key, np.nan))]\n","            return float(np.median(vals)) if len(vals) else np.nan\n","        frac = np.mean([\n","            (r.get(\"peak_r\", np.nan) > r.get(\"peak_r_null\", np.nan))\n","            for r in rows\n","            if np.isfinite(r.get(\"peak_r\", np.nan)) and np.isfinite(r.get(\"peak_r_null\", np.nan))\n","        ]) if any(np.isfinite(r.get(\"peak_r\", np.nan)) and np.isfinite(r.get(\"peak_r_null\", np.nan)) for r in rows) else np.nan\n","        return {\n","            \"median_peak_r\": med(\"peak_r\"),\n","            \"median_peak_lag_ms\": med(\"peak_lag_ms\"),\n","            \"median_peak_r_null\": med(\"peak_r_null\"),\n","            \"frac_r_gt_null\": float(frac) if np.isfinite(frac) else np.nan\n","        }\n","    lag_alignment = {\"pc1\": _summarize_lag_rows(rows_pc1), \"envelope\": _summarize_lag_rows(rows_env)}\n","\n","    # 6) 通道级 ROI（基于 Envelope）\n","    voicing_cols = np.where(percol_nan_mean > 0.95)[0].tolist()\n","    channel_roi_summary = compute_lag_stats_channelwise(\n","        eegs, snds, snds_rep, frame_ms=frame_ms, max_lag_ms=max_lag_ms,\n","        null_shift_ratio=null_shift_ratio, voicing_cols=voicing_cols\n","    )\n","\n","    # 7) 被试级 TRF\n","    trf_results_per_subject = run_trf_analysis_per_subject(\n","        eegs, snds, snds_rep, sids,\n","        voicing_cols=voicing_cols, frame_ms=frame_ms\n","    )\n","\n","    # 8) 段级 NaN 率\n","    per_segment_nan_rates = []\n","    for S in snds:\n","        overall, _ = nan_breakdown_per_segment(S)\n","        per_segment_nan_rates.append(float(overall))\n","\n","    results = {\n","        \"noise_ceiling_pc1\": noise_ceiling_pc1,\n","        \"lag_alignment\": lag_alignment,\n","        \"channel_roi_summary\": channel_roi_summary,\n","        \"trf_results_per_subject\": trf_results_per_subject,\n","        \"sound_nan_summary\": {\"per_segment_rates\": per_segment_nan_rates,\n","                              \"per_col_mean\": percol_nan_mean.tolist() if hasattr(percol_nan_mean, \"tolist\") else None},\n","        \"sound_repair_stats\": drop_stats,\n","        \"root_suffix_used\": root_suffix\n","    }\n","\n","    # 可选保存\n","    if save_dir:\n","        os.makedirs(save_dir, exist_ok=True)\n","        with open(os.path.join(save_dir, \"summary.json\"), \"w\") as f:\n","            json.dump(results, f, ensure_ascii=False, indent=2)\n","        # 逐段 ROI\n","        import csv\n","        with open(os.path.join(save_dir, \"channel_roi_per_segment.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.DictWriter(f, fieldnames=[\"peak_r\",\"peak_lag_ms\",\"peak_r_null\",\"best_ch\"])\n","            w.writeheader(); w.writerows(channel_roi_summary[\"per_segment\"])\n","        # 被试级 TRF\n","        with open(os.path.join(save_dir, \"trf_per_subject.json\"), \"w\") as f:\n","            json.dump(trf_results_per_subject[\"per_subject\"], f, ensure_ascii=False, indent=2)\n","        # 声学列修复统计\n","        with open(os.path.join(save_dir, \"sound_repair_stats.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.DictWriter(f, fieldnames=[\"D_in\",\"D_kept\"])\n","            w.writeheader(); w.writerows(drop_stats)\n","        # 段级NaN率\n","        with open(os.path.join(save_dir, \"sound_nan_rate_per_segment.csv\"), \"w\", newline=\"\") as f:\n","            w = csv.writer(f); w.writerow([\"nan_rate\"]); w.writerows([[x] for x in per_segment_nan_rates])\n","        print(f\"结果已保存到: {save_dir}\")\n","\n","    print(\"--- 数据分析管线完成 ---\")\n","    return results\n"],"metadata":{"id":"cqTU9fMGDDS2","executionInfo":{"status":"ok","timestamp":1760441797479,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["results = analyze_eeg_sound_data(root_dir, save_dir=\"/content/eeg_sound_results_from_wav\", root_suffix=\"feature_from_wav_causal\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ds9XX3qCa1O","executionInfo":{"status":"ok","timestamp":1760444427763,"user_tz":-180,"elapsed":2630282,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"27975a6d-ecc2-46ea-fc7a-cbec36f527f7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 开始数据分析管线 ---\n","[INFO] 使用 root_suffix='feature_from_wav_causal' 加载数据段\n","开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者:  25%|██▌       | 5/20 [00:28<01:01,  4.07s/it]"]},{"output_type":"stream","name":"stdout","text":["加载文件 VIE_RechLn4_Cer&LIY25m_EP002_129_WomenFury2_EEG_aligned.npy 时出错: No data left in file\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [01:20<00:00,  4.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1793 个数据段。\n","过滤结果：总 1793 段 -> 保留 1793 段 | 空T: 0, 空D: 0, 过短(<20帧): 0\n","EEG: 段数=1793, 含NaN段=0 (0.0%), 含Inf段=0 (0.0%)\n","Sound: 段数=1793, 含NaN段=0 (0.0%), 含Inf段=0 (0.0%)\n","\n","=== 声音特征 NaN 概览 ===\n","- 段级：含NaN的段 = 0/1793 (0.0%); 中位数NaN率 = 0.00%\n","- 列级（跨段平均）前10个最差列及其NaN率：\n","  列0: 平均NaN率=0.00%\n","  列1: 平均NaN率=0.00%\n","  列2: 平均NaN率=0.00%\n","  列3: 平均NaN率=0.00%\n","  列4: 平均NaN率=0.00%\n","  列5: 平均NaN率=0.00%\n","  列6: 平均NaN率=0.00%\n","  列7: 平均NaN率=0.00%\n","  列8: 平均NaN率=0.00%\n","  列9: 平均NaN率=0.00%\n"]},{"output_type":"stream","name":"stderr","text":["修复声音特征: 100%|██████████| 1793/1793 [00:02<00:00, 675.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["修复完成：平均保留列数 = 41.0  / 平均原始列数 = 41.0\n","\n","=== 基于 PC1 的分块噪声上限 ===\n","{\n","  \"r_eeg_blk_overall_PC1\": 0.693258824616112,\n","  \"r_sound_blk_overall_PC1\": 0.6428187346463753,\n","  \"r_max_blk_overall_PC1\": 0.6675625516924706\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Lag PC1 / Envelope: 100%|██████████| 1793/1793 [01:50<00:00, 16.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 时延（PC1↔PC1）汇总 ===\n","{\n","  \"median_peak_r\": 0.1427395589178009,\n","  \"median_peak_lag_ms\": 0.0,\n","  \"median_peak_r_null\": 0.14893642109793823,\n","  \"frac_r_gt_null\": 0.4796430563301729\n","}\n","\n","=== 时延（PC1↔Envelope）汇总 ===\n","{\n","  \"median_peak_r\": 0.1457437393733052,\n","  \"median_peak_lag_ms\": 0.0,\n","  \"median_peak_r_null\": 0.14751033550014306,\n","  \"frac_r_gt_null\": 0.4902398215281651\n","}\n"]},{"output_type":"stream","name":"stderr","text":["Channelwise ROI: 100%|██████████| 1793/1793 [17:35<00:00,  1.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== 通道级 ROI 汇总 ===\n","{\n","  \"median_peak_r\": 0.21002804880813247,\n","  \"median_peak_lag_ms\": 11.0,\n","  \"median_peak_r_null\": 0.13906479400341226,\n","  \"frac_r_gt_null\": 0.8901282766313441,\n","  \"top_channels\": [\n","    [\n","      10,\n","      174\n","    ],\n","    [\n","      1,\n","      145\n","    ],\n","    [\n","      8,\n","      99\n","    ],\n","    [\n","      28,\n","      82\n","    ],\n","    [\n","      30,\n","      76\n","    ],\n","    [\n","      17,\n","      72\n","    ],\n","    [\n","      14,\n","      70\n","    ],\n","    [\n","      2,\n","      70\n","    ],\n","    [\n","      13,\n","      63\n","    ],\n","    [\n","      11,\n","      61\n","    ]\n","  ]\n","}\n"]},{"output_type":"stream","name":"stderr","text":["TRF per subject: 100%|██████████| 15/15 [22:51<00:00, 91.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== TRF（总体）===\n","{\n","  \"median_of_subject_medians\": 0.0025876498736293607,\n","  \"median_of_subject_nulls\": 0.0015650909126277055,\n","  \"frac_subjects_better_than_null\": 0.5333333333333333,\n","  \"median_TRF_peak_ms_(>=0)\": 66.0\n","}\n","结果已保存到: /content/eeg_sound_results_from_wav\n","--- 数据分析管线完成 ---\n"]}]},{"cell_type":"code","source":["# ===== A. 多子带 TRF 补丁（贴进一个新单元运行）=====\n","\n","import numpy as np\n","from sklearn.model_selection import GroupKFold\n","\n","# --- 小工具：二阶差分惩罚矩阵（D^T D） ---\n","def _diff2_mat(n):\n","    if n < 3:\n","        return np.zeros((n, n), dtype=np.float64)\n","    D = np.zeros((n-2, n), dtype=np.float64)\n","    for i in range(n-2):\n","        D[i, i]   = 1.0\n","        D[i, i+1] = -2.0\n","        D[i, i+2] = 1.0\n","    return D.T @ D  # (n,n)\n","\n","# --- 设计矩阵：把 mel(B×T) 展成 [lag0全频 | lag1全频 | ...] -> (T, B*L) ---\n","def build_multiband_design(mel_TxB, lags_fr):\n","    mel = np.asarray(mel_TxB, dtype=np.float64)\n","    T, B = mel.shape\n","    L = len(lags_fr)\n","    X = np.zeros((T, B*L), dtype=np.float64)\n","    for j, Lg in enumerate(lags_fr):\n","        if Lg >= 0:\n","            X[Lg:, j*B:(j+1)*B] = mel[:T-Lg, :]\n","        else:\n","            X[:T+Lg, j*B:(j+1)*B] = mel[-Lg:, :]\n","    return X  # (T, B*L)\n","\n","# --- 频带 & 滞后联合平滑的岭回归（alpha*I + beta_lag*kron(I_B, D2_L) + beta_band*kron(D2_B, I_L)）---\n","def trf_fit_multiband(Xtr, ytr, B, L, alpha=10.0, beta_lag=10.0, beta_band=1.0, add_voicing=False, alpha_voicing=None):\n","    # Xtr: (N, P)  其中 P = B*L [+1 if voicing]\n","    P = Xtr.shape[1]\n","    # XtX / XtY\n","    XtX = Xtr.T @ Xtr\n","    XtY = Xtr.T @ ytr\n","\n","    # 正则块定位\n","    P0 = B*L  # 仅滞后块\n","    # alphaI\n","    A = XtX + alpha * np.eye(P)\n","    # 滞后方向二阶平滑（块对角）\n","    if beta_lag > 0 and L >= 3:\n","        D2_L = _diff2_mat(L)\n","        A[:P0, :P0] += beta_lag * np.kron(np.eye(B), D2_L)\n","    # 频带方向二阶平滑（跨频带）\n","    if beta_band > 0 and B >= 3:\n","        D2_B = _diff2_mat(B)\n","        A[:P0, :P0] += beta_band * np.kron(D2_B, np.eye(L))\n","    # voicing 列（如果有）：可给更强/更弱的岭\n","    if add_voicing and (P == P0 + 1) and (alpha_voicing is not None):\n","        A[P0, P0] += (alpha_voicing - alpha)\n","\n","    # 求解\n","    w = np.linalg.solve(A, XtY)\n","    return w  # (P,)\n","\n","# --- 方便从一段特征中取出 mel 子带与 RMS（约定：前 n_mels 列是 mel，最后一列是 RMS）---\n","def split_mel_rms_from_segment(Sseg, n_mels=40):\n","    S = np.asarray(Sseg, dtype=np.float64)\n","    T, D = S.shape\n","    if D < n_mels + 1:\n","        n_mels = max(1, D-1)  # 尽量向下兼容\n","    mel = S[:, :n_mels]\n","    rms = S[:, -1]\n","    return mel, rms\n","\n","# --- 简单 RMS→voicing 掩码（段内分位数阈值）---\n","def voicing_from_rms(rms, pct=60):\n","    rms = np.asarray(rms, dtype=np.float64)\n","    x = rms[np.isfinite(rms)]\n","    thr = np.percentile(x, pct) if x.size else 0.0\n","    return (rms > thr)\n","\n","# --- 计算多子带 TRF 的“峰滞后”（把每个滞后的 across-band L2 能量作为峰选择依据）---\n","def trf_peak_ms_from_weights(w, B, L, frame_ms=11.0):\n","    w0 = w[:B*L].reshape(L, B)  # (L, B)\n","    e = np.linalg.norm(w0, axis=1)  # 每个滞后的 across-band L2\n","    k = int(np.argmax(np.abs(e)))\n","    return float(k * frame_ms)\n","\n","# --- 每被试的多子带 TRF 评估（嵌套CV，ROI-in-train，含可选 voicing 与超参网格） ---\n","def eval_subject_trf_multiband(subject_id,\n","                               eeg_segments, sound_segments, subject_ids,\n","                               frame_ms=11.0, n_mels=40,\n","                               lags_ms=np.arange(0, 201, 11),   # 0..200ms\n","                               roi_topk=3,\n","                               add_voicing=True, voicing_pct=60,\n","                               alpha_grid=(1.0, 10.0, 100.0),\n","                               beta_lag_grid=(0.0, 10.0, 100.0),\n","                               beta_band_grid=(0.0, 1.0, 10.0),\n","                               global_offset_ms=0,\n","                               standardize_XY=True):\n","    # 依赖：fit_standardizer, apply_standardizer, zscore1d, highpass_moving_average, select_roi_channels_for_subject\n","    idx = [i for i, sid in enumerate(subject_ids) if sid == subject_id]\n","    if len(idx) < 8:\n","        return {\"subject\": subject_id, \"note\": \"too few segments\"}\n","    groups = np.arange(len(idx))\n","    outer = GroupKFold(n_splits=min(5, len(idx)))\n","\n","    # 滞后（帧）\n","    lags_fr = (np.array(lags_ms) / frame_ms).astype(int)\n","    L = len(lags_fr)\n","\n","    seg_corrs, seg_corrs_null, peak_lags = [], [], []\n","\n","    for tr_i, va_i in outer.split(np.zeros(len(idx)), groups=groups):\n","        tr_idx = [idx[i] for i in tr_i]\n","        va_idx = [idx[i] for i in va_i]\n","\n","        # --- 训练折内选 ROI（沿用你现有选择器：基于 envelope 的 top-k 通道）---\n","        roi = select_roi_channels_for_subject(\n","            eeg_segments, sound_segments, sound_segments,  # 这里 sound_repaired==sound_segments（已无NaN）\n","            tr_idx, top_k=roi_topk, frame_ms=frame_ms, max_lag_ms=200, voicing_cols=None\n","        )\n","\n","        # --- 构建数据集 ---\n","        def build_dataset(seg_indices):\n","            Xs, ys = [], []\n","            for k in seg_indices:\n","                E = eeg_segments[k]\n","                S = sound_segments[k]\n","                # mel & rms\n","                mel, rms = split_mel_rms_from_segment(S, n_mels=n_mels)\n","                # 全局正偏移（声音前移 = EEG滞后）\n","                if global_offset_ms and abs(global_offset_ms) > 1e-6:\n","                    shift = int(round(global_offset_ms / frame_ms))\n","                    if shift > 0:\n","                        # 前移：丢前面 shift 帧，后面补零\n","                        mel = np.vstack([mel[shift:], np.zeros((shift, mel.shape[1]))])\n","                        rms = np.concatenate([rms[shift:], np.zeros(shift)])\n","                    elif shift < 0:\n","                        # 负移（一般不用）\n","                        mel = np.vstack([np.zeros((-shift, mel.shape[1])), mel[:len(mel)+shift]])\n","                        rms = np.concatenate([np.zeros(-shift), rms[:len(rms)+shift]])\n","                # 设计矩阵（多子带）\n","                Xseg = build_multiband_design(mel, lags_fr)  # (T, B*L)\n","                # 可选：追加 voicing 1 列\n","                if add_voicing:\n","                    vm = voicing_from_rms(rms, pct=voicing_pct).astype(np.float64)\n","                    Xseg = np.hstack([Xseg[:len(vm)], vm.reshape(-1,1)])\n","                # 目标：ROI 通道平均，且高通\n","                ychs = []\n","                for ch in roi:\n","                    y = (E[:, ch] - E[:, ch].mean()) / (E[:, ch].std() if E[:, ch].std()>0 else 1.0)\n","                    y = highpass_moving_average(y, 15)\n","                    ychs.append(y[:Xseg.shape[0]])\n","                yseg = np.mean(np.vstack(ychs), axis=0) if len(ychs) else np.zeros(Xseg.shape[0])\n","                # 截齐\n","                T = min(Xseg.shape[0], len(yseg))\n","                Xs.append(Xseg[:T]); ys.append(yseg[:T])\n","            X = np.vstack(Xs); y = np.concatenate(ys)\n","            return X, y\n","\n","        Xtr_raw, ytr_raw = build_dataset(tr_idx)\n","        Xva_raw_list, yva_raw_list = [], []\n","        for k in va_idx:\n","            Xk, yk = build_dataset([k])\n","            Xva_raw_list.append(Xk); yva_raw_list.append(yk)\n","\n","        # 标准化\n","        if standardize_XY:\n","            Xmu, Xsd = fit_standardizer(Xtr_raw); Xtr = apply_standardizer(Xtr_raw, Xmu, Xsd)\n","            ytr, ymu, ysd = zscore1d(ytr_raw)\n","        else:\n","            Xmu, Xsd = np.zeros(Xtr_raw.shape[1]), np.ones(Xtr_raw.shape[1]); Xtr = Xtr_raw\n","            ytr = ytr_raw; ymu, ysd = 0.0, 1.0\n","\n","        # 内层验证（80/20）\n","        n = len(ytr); ntr = max(1, int(0.8*n))\n","        Xtr_i, ytr_i = Xtr[:ntr], ytr[:ntr]\n","        Xvl_i, yvl_i = Xtr[ntr:], ytr[ntr:]\n","\n","        # 超参网格\n","        B = min(n_mels, split_mel_rms_from_segment(sound_segments[tr_idx[0]], n_mels=n_mels)[0].shape[1])\n","        P0 = B*L\n","        best, best_hp = -np.inf, (10.0, 10.0, 1.0)\n","        for a in alpha_grid:\n","            for bl in beta_lag_grid:\n","                for bb in beta_band_grid:\n","                    w = trf_fit_multiband(Xtr_i, ytr_i, B, L, alpha=a, beta_lag=bl, beta_band=bb,\n","                                          add_voicing=add_voicing, alpha_voicing=a)\n","                    yhat = Xvl_i @ w\n","                    r = np.corrcoef(yvl_i, yhat)[0,1] if np.std(yvl_i)>0 and np.std(yhat)>0 else -np.inf\n","                    if np.isfinite(r) and r > best:\n","                        best, best_hp = r, (a, bl, bb)\n","\n","        a, bl, bb = best_hp\n","        w = trf_fit_multiband(Xtr, ytr, B, L, alpha=a, beta_lag=bl, beta_band=bb,\n","                              add_voicing=add_voicing, alpha_voicing=a)\n","\n","        # 记录“峰滞后”\n","        peak_lags.append(trf_peak_ms_from_weights(w, B, L, frame_ms=frame_ms))\n","\n","        # 外层验证\n","        for Xk_raw, yk_raw in zip(Xva_raw_list, yva_raw_list):\n","            Xk = apply_standardizer(Xk_raw, Xmu, Xsd) if standardize_XY else Xk_raw\n","            yk = (yk_raw - ymu) / (ysd if ysd>0 else 1.0) if standardize_XY else yk_raw\n","            yhat = Xk @ w\n","            rk = np.corrcoef(yk, yhat)[0,1] if np.std(yk)>0 and np.std(yhat)>0 else np.nan\n","            # 置换对照：循环移位\n","            sh = max(1, int(0.33*len(yk)))\n","            yperm = np.roll(yk, sh)\n","            rk0 = np.corrcoef(yperm, yhat)[0,1] if np.std(yperm)>0 and np.std(yhat)>0 else np.nan\n","            seg_corrs.append(rk); seg_corrs_null.append(rk0)\n","\n","    seg_corrs = np.array(seg_corrs, dtype=np.float64)\n","    seg_corrs_null = np.array(seg_corrs_null, dtype=np.float64)\n","    valid = np.isfinite(seg_corrs) & np.isfinite(seg_corrs_null)\n","\n","    res = {\n","        \"subject\": subject_id,\n","        \"n_segments_eval\": int(valid.sum()),\n","        \"median_pred_r\": float(np.median(seg_corrs[valid])) if valid.any() else np.nan,\n","        \"median_pred_r_null\": float(np.median(seg_corrs_null[valid])) if valid.any() else np.nan,\n","        \"frac_r_better_than_null\": float(np.mean(seg_corrs[valid] > seg_corrs_null[valid])) if valid.any() else np.nan,\n","        \"median_trf_peak_ms_(>=0)\": float(np.median(peak_lags)) if len(peak_lags) else np.nan,\n","        \"note\": f\"Multi-band TRF | B={n_mels}, lags={lags_ms[0]}..{lags_ms[-1]}ms | ridge + lag/band smooth\"\n","    }\n","    return res\n","\n","# --- 批量跑所有被试（多子带 TRF 版本） ---\n","def run_trf_analysis_per_subject_multiband(eeg_segments, sound_segments, subject_ids,\n","                                           frame_ms=11.0, n_mels=40,\n","                                           lags_ms=np.arange(0, 201, 11),\n","                                           global_offset_ms=0):\n","    subs = sorted(set(subject_ids))\n","    out = []\n","    for sid in subs:\n","        out.append(eval_subject_trf_multiband(\n","            sid, eeg_segments, sound_segments, subject_ids,\n","            frame_ms=frame_ms, n_mels=n_mels, lags_ms=lags_ms,\n","            global_offset_ms=global_offset_ms\n","        ))\n","    vals = [r for r in out if np.isfinite(r.get(\"median_pred_r\", np.nan))]\n","    if vals:\n","        med_r  = float(np.median([r[\"median_pred_r\"] for r in vals]))\n","        med_r0 = float(np.median([r[\"median_pred_r_null\"] for r in vals]))\n","        frac   = float(np.mean([r[\"median_pred_r\"] > r[\"median_pred_r_null\"] for r in vals]))\n","        med_pk = float(np.median([r[\"median_trf_peak_ms_(>=0)\"] for r in vals if np.isfinite(r[\"median_trf_peak_ms_(>=0)\"])])) if any(np.isfinite(r[\"median_trf_peak_ms_(>=0)\"]) for r in vals) else np.nan\n","        overall = {\"median_of_subject_medians\": med_r, \"median_of_subject_nulls\": med_r0,\n","                   \"frac_subjects_better_than_null\": frac, \"median_TRF_peak_ms_(>=0)\": med_pk}\n","    else:\n","        overall = {\"median_of_subject_medians\": np.nan, \"median_of_subject_nulls\": np.nan,\n","                   \"frac_subjects_better_than_null\": np.nan, \"median_TRF_peak_ms_(>=0)\": np.nan}\n","    return {\"per_subject\": out, \"overall_summary\": overall}\n"],"metadata":{"id":"84OoHwzxL5pE","executionInfo":{"status":"ok","timestamp":1760444428245,"user_tz":-180,"elapsed":62,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# 用你已经加载好的段（确保 root_suffix='feature_from_wav_causal'）\n","eegs, snds, sids = load_segments_with_subject_ids(root_dir, root_suffix='feature_from_wav_causal')\n","\n","# 直接跑多子带 TRF（不做全局偏移；后面的补丁 B 会自动扫偏移）\n","trf_mb = run_trf_analysis_per_subject_multiband(\n","    eegs, snds, sids, frame_ms=11.0, n_mels=40, lags_ms=np.arange(0,201,11), global_offset_ms=0\n",")\n","print(trf_mb[\"overall_summary\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SoocFgmL-Ub","executionInfo":{"status":"ok","timestamp":1760447486128,"user_tz":-180,"elapsed":3057875,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"3990ae84-7803-471d-ff88-46dfe9524c0c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者:  20%|██        | 4/20 [00:25<01:38,  6.17s/it]"]},{"output_type":"stream","name":"stdout","text":["加载文件 VIE_RechLn4_Cer&LIY25m_EP002_129_WomenFury2_EEG_aligned.npy 时出错: No data left in file\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [01:00<00:00,  3.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1793 个数据段。\n","{'median_of_subject_medians': -0.0014900903102061573, 'median_of_subject_nulls': -0.00995797873044558, 'frac_subjects_better_than_null': 0.8, 'median_TRF_peak_ms_(>=0)': 66.0}\n"]}]},{"cell_type":"code","source":["# ===== B. 全局偏移扫描补丁（贴进新单元运行）=====\n","\n","import numpy as np\n","from tqdm import tqdm\n","\n","def _env_from_mel(S, n_mels=40):\n","    \"\"\"从段的声学特征中抽 mel 子带并构造 L2 包络（已 z 的 mel 更佳，这里直接按输入做）。\"\"\"\n","    S = np.asarray(S, dtype=np.float64)\n","    mel = S[:, :min(n_mels, S.shape[1]-1)]\n","    e = np.sqrt((mel**2).sum(axis=1))\n","    return (e - e.mean())/(e.std() if e.std()>0 else 1.0)\n","\n","def _shift_forward_matrix(S, shift_ms, frame_ms):\n","    \"\"\"声音前移（EEG滞后）：+shift_ms 会把 S 向前滚动，尾部补零。\"\"\"\n","    k = int(round(shift_ms / frame_ms))\n","    if k <= 0:\n","        return S.copy()\n","    T, D = S.shape\n","    out = np.zeros_like(S)\n","    if k < T:\n","        out[k:] = S[:T-k]\n","    return out\n","\n","def roi_score_with_offset(eeg_segments, sound_segments, frame_ms=11.0, max_lag_ms=300, offset_ms=0):\n","    \"\"\"对所有段，计算“通道级 ROI”在给定全局偏移下的峰相关中位数（简化版）。\"\"\"\n","    max_lag = int(round(max_lag_ms/frame_ms))\n","    rs = []\n","    for E, S in zip(eeg_segments, sound_segments):\n","        Ssh = _shift_forward_matrix(S, offset_ms, frame_ms)\n","        ee = _env_from_mel(Ssh)\n","        best = -np.inf\n","        for ch in range(E.shape[1]):\n","            y = (E[:, ch] - E[:, ch].mean()) / (E[:, ch].std() if E[:, ch].std()>0 else 1.0)\n","            y = highpass_moving_average(y, 15)\n","            T = min(len(y), len(ee))\n","            y0 = (y[:T] - y[:T].mean())/(y[:T].std() if y[:T].std()>0 else 1.0)\n","            e0 = (ee[:T] - ee[:T].mean())/(ee[:T].std() if ee[:T].std()>0 else 1.0)\n","            vals = []\n","            for lag in range(-max_lag, max_lag+1):\n","                if lag >= 0:\n","                    a, b = y0[lag:], e0[:T-lag]\n","                else:\n","                    a, b = y0[:T+lag], e0[-lag:]\n","                if len(a) < 20 or a.std()==0 or b.std()==0:\n","                    vals.append(np.nan); continue\n","                vals.append(np.corrcoef(a, b)[0,1])\n","            r = np.nanmax(vals)\n","            if np.isfinite(r) and r > best:\n","                best = r\n","        if np.isfinite(best):\n","            rs.append(best)\n","    return float(np.median(rs)) if rs else np.nan\n","\n","def pick_global_offset_ms(eeg_segments, sound_segments, candidates_ms=(0,33,55,88,121), frame_ms=11.0, max_lag_ms=300):\n","    scores = {}\n","    for m in candidates_ms:\n","        scores[m] = roi_score_with_offset(eeg_segments, sound_segments, frame_ms=frame_ms, max_lag_ms=max_lag_ms, offset_ms=m)\n","    # 选最高的；若并列，取偏移较小者\n","    best = sorted(scores.items(), key=lambda kv: (-np.nan_to_num(kv[1], nan=-np.inf), kv[0]))[0][0]\n","    return best, scores\n","\n","# —— 一键：先扫偏移，再跑多子带 TRF（补丁 A 里的函数）——\n","def run_multiband_trf_with_auto_offset(root_dir, root_suffix='feature_from_wav_causal',\n","                                       frame_ms=11.0, n_mels=40, lags_ms=np.arange(0,201,11),\n","                                       offset_candidates=(0,33,55,88,121)):\n","    # 载入段\n","    eegs, snds, sids = load_segments_with_subject_ids(root_dir, root_suffix=root_suffix)\n","    # 简单过滤（若你已有 filter_and_summarize，可在此调用）\n","    # 这里默认你的数据已经是有效帧数\n","    # 扫描偏移\n","    best_off, all_scores = pick_global_offset_ms(eegs, snds, candidates_ms=offset_candidates, frame_ms=frame_ms)\n","    print(\"全局偏移扫描：\", all_scores, \" → 选择\", best_off, \"ms\")\n","\n","    # 跑多子带 TRF\n","    trf_mb = run_trf_analysis_per_subject_multiband(\n","        eegs, snds, sids, frame_ms=frame_ms, n_mels=n_mels, lags_ms=lags_ms,\n","        global_offset_ms=best_off\n","    )\n","    return {\"best_offset_ms\": best_off, \"offset_scores\": all_scores, \"trf_multiband\": trf_mb}\n"],"metadata":{"id":"q1j-GU0sL_Ss","executionInfo":{"status":"ok","timestamp":1760447486158,"user_tz":-180,"elapsed":26,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["res_auto = run_multiband_trf_with_auto_offset(\n","    root_dir, root_suffix='feature_from_wav_causal',\n","    frame_ms=11.0, n_mels=40, lags_ms=np.arange(0,201,11),\n","    offset_candidates=(0,33,55,88,121)\n",")\n","print(\"最佳全局偏移(ms):\", res_auto[\"best_offset_ms\"])\n","print(\"多子带 TRF 总体：\", res_auto[\"trf_multiband\"][\"overall_summary\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fq9lwmk6MA0N","executionInfo":{"status":"ok","timestamp":1760452915156,"user_tz":-180,"elapsed":5428997,"user":{"displayName":"Mahler David","userId":"01405886190187025860"}},"outputId":"3275130d-e504-4387-8095-bf987612af38"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["开始从根目录 '/content/drive/MyDrive/data' 加载数据段及被试者ID...\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者:  20%|██        | 4/20 [00:12<00:48,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["加载文件 VIE_RechLn4_Cer&LIY25m_EP002_129_WomenFury2_EEG_aligned.npy 时出错: No data left in file\n"]},{"output_type":"stream","name":"stderr","text":["处理被试者: 100%|██████████| 20/20 [00:47<00:00,  2.36s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","加载完成！总共加载了 1793 个数据段。\n","全局偏移扫描： {0: 0.13130889287633654, 33: 0.13601997784196465, 55: 0.13779113666156684, 88: 0.13576752771856193, 121: 0.13391909700439705}  → 选择 55 ms\n","最佳全局偏移(ms): 55\n","多子带 TRF 总体： {'median_of_subject_medians': 0.0018318710500284817, 'median_of_subject_nulls': -0.004173565441407767, 'frac_subjects_better_than_null': 0.6, 'median_TRF_peak_ms_(>=0)': 143.0}\n"]}]}]}